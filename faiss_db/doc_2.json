{
  "0": "HAL Id: hal-03849387\nhttps://hal.science/hal-03849387v1\nSubmitted on 13 Dec 2022\nHAL is a multi-disciplinary open access\narchive for the deposit and dissemination of sci-\nentific research documents, whether they are pub-\nlished or not. The documents may come from\nteaching and research institutions in F rance or\nabroad, or from public or private research centers.",
  "1": "L’archive ouverte pluridisciplinaire HAL , est\ndestinée au dépôt et à la diffusion de documents\nscientifiques de niveau recherche, publiés ou non,\némanant des établissements d’enseignement et de\nrecherche français ou étrangers, des laboratoires\npublics ou privés. Introduction à l’intelligence artificielle et aux modèles\ngénératifs\nPierre-Alexandre Mattei, Serena Villata\nT o cite this version: Pierre-Alexandre Mattei, Serena Villata.",
  "2": "Introduction à l’intelligence artificielle et aux modèles\ngénératifs. Bruno Martin; Sara Riva. Informatique Mathématique: Une photographie en 2022, CNRS\nEditions, 2022. ￿hal-03849387￿Chapitre 1\nIntroduction à l’intelligence\nartiﬁcielle et aux modèles\ngénératifs\nPierre-Alexandre Mattei, Serena Villata Université",
  "3": "Côte d’Azur, Inria\nL’intelligence artiﬁcielle est un champ polymorphe, caractérisé par son\ninterdisciplinarité et sa situation particulière, au carrefour de plusieurs\nbranches des mathématiques et de l’informatique. On offrira ici un panorama\ndes différentes familles d’intelligence artiﬁcielle, ainsi que leur articulation\nhistorique. Puis, nous traiterons un exemple d’approche récente en détail :\ncelui des modèles statistiques génératifs.\n1.1 Introduction",
  "4": "Le terme \"intelligence artiﬁcielle\" (ci-après \"IA\") a été inventé par\nJohn McCarthy en 1956, à l’occasion d’un séminaire de deux mois (qu’il a\norganisé au Dartmouth College à Hanover, New Hampshire, États-Unis)\nqui a eu le mérite de faire se rencontrer dix chercheurs américains (sur\nla théorie des automates, les réseaux de neurones et l’intelligence) et de\ndonner l’imprimatur au terme \"intelligence artiﬁcielle\" comme nom ofﬁciel\nd’un nouveau domaine de recherche.",
  "5": "Depuis lors, l’IA s’est établie et a évolué; aujourd’hui, elle est recon-\nnue comme une branche autonome, bien qu’elle soit liée à l’informatique,\naux mathématiques, aux sciences cognitives, à la neurobiologie et à la\nphilosophie.iv Chapitre 1. IA et modèles génératifs De nombreuses déﬁnitions ont été données à ce sujet : elles diffèrent\npar les tâches effectuées par les machines que l’IA cherche à construire.",
  "6": "Ces tâches peuvent être classées selon deux dimensions orthogonales [ 20]:\nles machines qui pensent ou agissent, et les machines qui simulent les\nhumains (ou se comportent de manière rationnelle). Quatre classes au total,\nselon que les machines : pensent comme des humains, agissent comme des\nhumains, pensent rationnellement, agissent rationnellement.",
  "7": "Quatre ap-\nproches distinctes de la recherche sur l’IA, donc, qui sont toutes activement\npoursuivies.\nL’objectif de l’approche \"les machines pensent comme les humains\"\nest de reproduire le raisonnement humain dans les machines. Elle peut se\nfaire à deux niveaux : en imitant les méthodes de raisonnement ou en re-\nproduisant le fonctionnement du cerveau.",
  "8": "Dans le premier cas, les sciences\ncognitives nous fournissent un point de départ important, obtenu par l’in-\ntrospection et les expériences psychologiques. Dans le second cas, c’est la\nneurobiologie qui nous fournit un modèle approprié. Ce premier critère\nvise donc à produire des automates qui, non seulement se comportent\ncomme des humains, mais aussi \"fonctionnent\npar les tâches effectuées par les machines que l’IA cherche à construire.",
  "9": "Ces tâches peuvent être classées selon deux dimensions orthogonales [ 20]:\nles machines qui pensent ou agissent, et les machines qui simulent les\nhumains (ou se comportent de manière rationnelle). Quatre classes au total,\nselon que les machines : pensent comme des humains, agissent comme des\nhumains, pensent rationnellement, agissent rationnellement.",
  "10": "Quatre ap-\nproches distinctes de la recherche sur l’IA, donc, qui sont toutes activement\npoursuivies.\nL’objectif de l’approche \"les machines pensent comme les humains\"\nest de reproduire le raisonnement humain dans les machines. Elle peut se\nfaire à deux niveaux : en imitant les méthodes de raisonnement ou en re-\nproduisant le fonctionnement du cerveau.",
  "11": "Dans le premier cas, les sciences\ncognitives nous fournissent un point de départ important, obtenu par l’in-\ntrospection et les expériences psychologiques. Dans le second cas, c’est la\nneurobiologie qui nous fournit un modèle approprié.",
  "12": "Ce premier critère\nvise donc à produire des automates qui, non seulement se comportent\ncomme des humains, mais aussi \"fonctionnent\" comme des humains.\nL’objectif de l’approche des \"machines qui se comportent comme des\nhumains\" est de produire des machines qu’il est impossible de distinguer\ndes humains.",
  "13": "Cette propriété a été mieux déﬁnie par Alan Turing qui, dans\nun article de 1950 [ 26], a proposé le test qui porte son nom : un \"juge\" est\nautorisé à poser des questions écrites à un \"sujet\" et, sur la base des réponses,\ndoit décider s’il s’agit d’un humain ou d’une machine.",
  "14": "Pour réussir le test\nde Turing, une machine doit présenter les capacités suivantes :\n—le traitement du langage naturel, aﬁn de communiquer efﬁcace-\nment dans la langue du juge;\n—la représentation des connaissances, aﬁn de mémoriser ce que l’on\nsait ou ce que l’on importe;\n—le raisonnement automatique, pour déduire (produire), à partir de\nses propres connaissances, les réponses au juge;\n—l’apprentissage automatique, pour augmenter sa base de connais-\nsances.",
  "15": "Le test de Turing n’implique pas d’interaction physique entre le juge\net la machine, car cela n’est pas nécessaire. Si l’on veut, on peut penser\nà un test de Turing total dans lequel, au lieu de réponses écrites, le juge\nreçoit un signal audio-vidéo, et a la possibilité de faire passer des objets à la\nmachine par une fente. Dans ce cas, la machine doit également présenter les\ncapacités suivantes : la vision artiﬁcielle, pour reconnaître les objets reçus; la\nrobotique, pour les manipuler;",
  "16": "le traitement de la parole, pour comprendre\nles questions du juge et y répondre. Le test de Turing total rappelle le test1.1. Introduction v\nVoight-Kampf du ﬁlm Blade Runner, grâce auquel les policiers distinguent\nles androïdes des humains. L’approche de la \"machines pensant rationnellement\" ne s’intéresse\npas aux machines qui fonctionnent comme des humains, mais uniquement\nau raisonnement rationnel, le terme \"rationnel\"",
  "17": "étant précisément déﬁni par\nles mathématiques, y compris les techniques que les humains n’utilisent\npas naturellement. La logique, par exemple, est l’étude de la manière de\nmener un raisonnement imparable. La logique joue un rôle important dans\nl’IA, même si l’on s’attend initialement à ce qu’elle ne soit pas utilisée par\nles humains ou très peu.",
  "18": "De même, la dernière des quatre classes alternatives d’IA se concentre\nsur l’approche \"machines agissant rationnellement\" qui utilise la déﬁnition\nde \"l’action rationnelle\" fournie en économie, à savoir : la sélection d’ac-\ntions menant au meilleur résult\n; la\nrobotique, pour les manipuler; le traitement de la parole, pour comprendre\nles questions du juge et y répondre. Le test de Turing total rappelle le test1.1.",
  "19": "Introduction v\nVoight-Kampf du ﬁlm Blade Runner, grâce auquel les policiers distinguent\nles androïdes des humains. L’approche de la \"machines pensant rationnellement\" ne s’intéresse\npas aux machines qui fonctionnent comme des humains, mais uniquement\nau raisonnement rationnel, le terme \"rationnel\" étant précisément déﬁni par\nles mathématiques, y compris les techniques que les humains n’utilisent\npas naturellement.",
  "20": "La logique, par exemple, est l’étude de la manière de\nmener un raisonnement imparable. La logique joue un rôle important dans\nl’IA, même si l’on s’attend initialement à ce qu’elle ne soit pas utilisée par\nles humains ou très peu.",
  "21": "De même, la dernière des quatre classes alternatives d’IA se concentre\nsur l’approche \"machines agissant rationnellement\" qui utilise la déﬁnition\nde \"l’action rationnelle\" fournie en économie, à savoir : la sélection d’ac-\ntions menant au meilleur résultat, ou au meilleur résultat attendu s’il existe\ndes éléments d’imprévisibilité. L’objectif de cette approche est de créer un\nagent, une entité capable d’agir dans un environnement, aﬁn d’atteindre\nun ou plusieurs objectifs.",
  "22": "L’agent utilisera un raisonnement rationnel pour\nchoisir les actions à effectuer, mais dans certains cas, il devra réagir à des\nstimuli environnementaux si rapidement qu’il \"outrepassera\" son choix\n(par exemple, lorsqu’une inaction menace son existence). Si l’on touche\nquelque chose de chaud, on réagit en retirant immédiatement la main,\nsans raisonnement conscient; de même, l’agent, dans certaines situations,\ndoit être capable d’agir sans raisonner.",
  "23": "Les agents peuvent être de deux\ntypes : uniquement logiciels, auquel cas ils sont appelés softbots , ou à la fois\nmatériels et logiciels, alors appelés robots . Dans le cas des softbots, l’envi-\nronnement externe dans lequel ils opèrent est le Web, où ils interagissent\navec des humains et d’autres softbots. C’est actuellement l’approche la plus\npoursuivie, car elle promet les résultats pratiques les plus utiles.",
  "24": "Aﬁn de présenter les différentes techniques proposées par l’IA, nous\nles diviserons en deux grandes classes : symbolique et subsymbolique. La\npremière propose d’automatiser le raisonnement et l’action, en représentant\nles situations objet de l’analyse par des symboles compréhensibles par l’être\nhumain, et en les traitant par des algorithmes.",
  "25": "La dernière, en revanche,\nne représente pas explicitement les connaissances de manière directement\ncompréhensible, et est basées sur la reproduction de phénomènes naturels\nà l’aide de méthodes statistiques. Nous détaillerons ensuite un exemple de\ncette approche statistique, à travers l’étude de modèles à variables latentes.",
  "26": "Les techniques symboliques ont été le paradigme dominant de l’IA\ndu milieu des années 1950 à la ﬁn des années 1980 et ont été appelées\nGOFAI (\"Good Old-Fashioned Artiﬁcial Intelligence\") dans [ 5]. Les tech-\nniques subsymboliques, et en particulier les réseaux de neurones, ont prisvi Chapitre 1. IA et modèles génératifs\nleur essor depuis les années 1990 et ont remporté d’importants succès\ndans divers domaines tels que la vision par ordinateur.",
  "27": "Récemment, la\nrecherche s’est orientée vers la combinaison de techniques symboliques et\nsubsymboliques.\n1.2 IA symbolique\nParmi les techniques symboliques, nous décrirons la recherche dans\nl’espace des états, le raisonnement automatique et l’apprentissage automa-\ntique.\n1.2.1 Recherche dans l’espace des\n en revanche ,\nne représente pas explicitement les connaissances de manière directement\ncompréhensible, et est basées sur la reproduction de phénomènes naturels\nà l’aide de méthodes statistiques.",
  "28": "Nous détaillerons ensuite un exemple de\ncette approche statistique, à travers l’étude de modèles à variables latentes. Les techniques symboliques ont été le paradigme dominant de l’IA\ndu milieu des années 1950 à la ﬁn des années 1980 et ont été appelées\nGOFAI (\"Good Old-Fashioned Artiﬁcial Intelligence\") dans [ 5]. Les tech-\nniques subsymboliques, et en particulier les réseaux de neurones, ont prisvi Chapitre 1.",
  "29": "IA et modèles génératifs\nleur essor depuis les années 1990 et ont remporté d’importants succès\ndans divers domaines tels que la vision par ordinateur. Récemment, la\nrecherche s’est orientée vers la combinaison de techniques symboliques et\nsubsymboliques.\n1.2 IA symbolique\nParmi les techniques symboliques, nous décrirons la recherche dans\nl’espace des états, le raisonnement automatique et l’apprentissage automa-\ntique.\n1.2.1 Recherche dans l’espace des états",
  "30": "Cette technique est utilisée lorsque l’on veut choisir une série d’actions\nmenant d’un état initial à un ou plusieurs états ﬁnaux souhaités. Les condi-\ntions, pour qu’elle soit utilisée, sont que l’état du monde extérieur puisse\nêtre représenté de manière concise (sous forme symbolique), que les actions\ndisponibles puissent être exprimées sous forme de règles de passage d’un\nétat à l’autre, et qu’il existe un test pour établir si un état est ﬁnal.",
  "31": "Examinons un exemple de problème qui peut être traité de cette ma-\nnière. Dans le jeu de huit (ou puzzle de huit), nous avons un échiquier de\ntrois cases sur trois, dans lequel huit cases sont occupées par huit tuiles nu-\nmérotées de 1 à 8 et une case est vide. Les mouvements possibles consistent\nà déplacer une tuile numérotée adjacente vers la tuile vide. Pour ce pro-\nblème, \"l’état\" consiste en la position des huit tuiles numérotées.",
  "32": "Le but est\nde trier les tuiles de 1 à 8, en essayant de faire le moins de déplacements\npossible.\nC’est un problème qui semble exiger de l’intelligence : un être humain\nle résoudrait en essayant différents mouvements et en tentant de prédire le\nrésultat. La méthode de résolution proposée par l’IA consiste à effectuer une\nrecherche dans l’espace des états possibles.",
  "33": "À cette ﬁn, on peut représenter\n\"l’espace\" comme un arbre dans lequel chaque nœud correspond à un \"état\".\nLa racine de l’arbre est l’état initial, les enfants d’un nœud sont les états qui\npeuvent être atteints à partir de l’état associé au nœud en appliquant un\nseul déplacement. Le problème est résolu lorsqu’un chemin de l’état initial à un état\nﬁnal a été trouvé. En général, il ne sufﬁt pas de trouver une solution, mais\ncelle qui a le coût minimum.",
  "34": "Il est donc nécessaire de déﬁnir un \"coût\" :\nnormalement, un coût est attribué aux différents coups, et le coût d’un\nchemin est mesuré comme la somme des coûts des coups qui le composent.1.2. IA symbolique vii\nDans le cas du jeu de huit, chaque coup coûte 1, et on cherche la solution\nnécessitant le nombre minimal de coups. Un autre problème similaire est le suivant.",
  "35": "Le problème \"missionnaires\net cannibales\" consiste à faire traverser une rivière à 3 missionnaires et 3\ncannibales, en utilisant un bateau et en empêchant les cannibales de manger\nles missionnaires (lorsqu’ils sont plus nombreux sur les deux rives). Le\nbateau ne peut contenir que deux personnes à la\n’arbre est l’état initial, les enfants d’un nœud sont les états qui\npeuvent être atteints à partir de l’état associé au nœud en appliquant un\nseul déplacement.",
  "36": "Le problème est résolu lorsqu’un chemin de l’état initial à un état\nﬁnal a été trouvé. En général, il ne sufﬁt pas de trouver une solution, mais\ncelle qui a le coût minimum. Il est donc nécessaire de déﬁnir un \"coût\" :\nnormalement, un coût est attribué aux différents coups, et le coût d’un\nchemin est mesuré comme la somme des coûts des coups qui le composent.1.2. IA symbolique vii\nDans le cas du jeu de huit, chaque coup coûte 1, et on cherche la solution\nnécessitant le nombre minimal de coups.",
  "37": "Un autre problème similaire est le suivant. Le problème \"missionnaires\net cannibales\" consiste à faire traverser une rivière à 3 missionnaires et 3\ncannibales, en utilisant un bateau et en empêchant les cannibales de manger\nles missionnaires (lorsqu’ils sont plus nombreux sur les deux rives). Le\nbateau ne peut contenir que deux personnes à la fois et doit être dirigé par\nau moins une personne pour se déplacer d’un côté à l’autre de la rivière.",
  "38": "L’état de ce problème peut être représenté à l’aide d’un triplet de nombres,\ndans lequel les deux premiers quantiﬁent les missionnaires et les cannibales\nsur la banque initiale, et le troisième est égal à 1 si le bateau est sur la rive\ninitiale, et 0 s’il est sur l’autre rive. L’état initial est (3,3,1), l’état ﬁnal est\n(0,0,0) et un état possible (2,2,1) indique qu’il y a deux missionnaires et deux\ncannibales sur la rive initiale et que le bateau est sur la rive initiale.",
  "39": "Cinq\nopérations sont possibles : traverser la rivière avec deux missionnaires,\navec deux cannibales, avec un missionnaire et un cannibale, avec un seul\ncannibale ou avec un seul missionnaire.",
  "40": "Toutes les opérations ne sont pas\nautorisées dans tous les états : par exemple, à partir de l’état (2,2,1), il\nn’est pas possible d’appliquer l’opération \"traverser la rivière avec un\nmissionnaire\" car sur la rive initiale il resterait un missionnaire et deux\ncannibales, et alors les cannibales mangeraient le missionnaire. Le coût,\ndans ce cas, est unitaire pour toutes les opérations, on cherche donc des\nsolutions avec le minimum de traversées de rivière.",
  "41": "Passons à des problèmes réels, comme le \"calcul d’itinéraire\", qui\nconsiste à aller d’un endroit à un autre au coût minimum, en passant par\ndes endroits intermédiaires, avec un coût associé à chaque lien. Un exemple\nest le voyage en voiture d’une ville à une autre : les liens sont les routes et\nle coût peut être la distance ou le temps nécessaire pour parcourir ce lien.",
  "42": "Si vous voyagez en avion, les liens correspondent aux vols disponibles, et\nle coût peut correspondre à la durée ou au prix du vol. Les \"états\" sont les\nlieux, et les mouvements disponibles consistent à utiliser l’un des liens du\nlieu actuel pour se déplacer vers un autre lieu.\nComment résoudre les problèmes de recherche? L’espace de recherche\ndoit être généré et parcouru à partir du nœud initial jusqu’à ce que l’on\ntrouve un état qui passe le test d’état ﬁnal par vériﬁcation;",
  "43": "lorsque le test\néchoue, le nœud doit être \"étendu\", ses successeurs générés à l’aide de\ndéplacements ou d’opérateurs possibles, et examinés jusqu’à ce que l’un\nd’entre eux passe le test, ou jusqu’à ce que tout l’espace des états soit\nexploré. L’arbre de recherche est\nroit à un autre au coût minimum, en passant par\ndes endroits intermédiaires, avec un coût associé à chaque lien.",
  "44": "Un exemple\nest le voyage en voiture d’une ville à une autre : les liens sont les routes et\nle coût peut être la distance ou le temps nécessaire pour parcourir ce lien. Si vous voyagez en avion, les liens correspondent aux vols disponibles, et\nle coût peut correspondre à la durée ou au prix du vol. Les \"états\" sont les\nlieux, et les mouvements disponibles consistent à utiliser l’un des liens du\nlieu actuel pour se déplacer vers un autre lieu.\nComment résoudre les problèmes de recherche?",
  "45": "L’espace de recherche\ndoit être généré et parcouru à partir du nœud initial jusqu’à ce que l’on\ntrouve un état qui passe le test d’état ﬁnal par vériﬁcation; lorsque le test\néchoue, le nœud doit être \"étendu\", ses successeurs générés à l’aide de\ndéplacements ou d’opérateurs possibles, et examinés jusqu’à ce que l’un\nd’entre eux passe le test, ou jusqu’à ce que tout l’espace des états soit\nexploré. L’arbre de recherche est ainsi généré progressivement.",
  "46": "Les algorithmes de recherche dans l’espace d’état diffèrent par le choixviii Chapitre 1. IA et modèles génératifs\ndu nœud à développer (stratégie de recherche). Les deux stratégies les plus\ncourantes sont la recherche en profondeur et la recherche en largeur.\nDans la recherche en profondeur, le nœud ayant la plus grande pro-\nfondeur qui a été généré mais pas encore développé est toujours développé.",
  "47": "Cela signiﬁe que l’on procède d’abord en profondeur jusqu’à ce que l’on\narrive à un nœud qui ne peut plus être développé ou pour lequel on ne peut\npas trouver de solution. Dans le premier cas, on part des nœuds du niveau\nde profondeur précédent et ainsi de suite. Dans la recherche en largeur,\npar contre, les nœuds de moindre profondeur qui ont été générés mais\npas encore développés sont toujours développés.",
  "48": "Dans ce cas, la racine\nde l’arbre est développée en premier, puis tous ses enfants, puis tous les\nenfants des enfants et ainsi de suite.\n1.2.2 Raisonnement automatique\nLe raisonnement automatique est l’utilisation de connaissances aﬁn\nd’en déduire de nouvelles. À cette ﬁn, il est nécessaire de représenter\nles connaissances dans un format qui peut être stocké par un ordinateur\net utilisé pour faire des inférences.",
  "49": "Ces exigences limitent le format de\nreprésentation aux langages formels, c’est-à-dire aux langages dont la\nsyntaxe et la sémantique sont précisément déﬁnies.\nL’un des langages formels les plus étudiés est la logique. Elle trouve\nson origine dans la philosophie et les mathématiques de la Grèce antique.",
  "50": "Le père fondateur de la logique en tant que discipline autonome peut être\nconsidéré comme Aristote (vers 384-321 av. J.-C.), tandis que Chrysippe de\nSoli (vers 280-205 av. J.-C.), de l’école stoïcienne, a déﬁni les connecteurs\nlogiques, les axiomes et les règles fondamentales de la logique proposition-\nnelle.",
  "51": "La naissance de la logique mathématique moderne remonte à George\nBoole (1815-1864), qui a publié en 1847 une méthode permettant de décrire\nla théorie des syllogismes aristotéliciens et de la logique propositionnelle\nsous la forme d’équations algébriques, et a proposé une procédure méca-\nnique pour leur résolution.",
  "52": "Gottlob Frege (1848-1925) a été le premier à\ndévelopper un système d’axiomes et de règles pour la logique du premier\nordre, dépassant ainsi les limites imposées par les syllogismes et la logique\npro\n des langages formels les plus étudiés est la logique. Elle trouve\nson origine dans la philosophie et les mathématiques de la Grèce antique.",
  "53": "Le père fondateur de la logique en tant que discipline autonome peut être\nconsidéré comme Aristote (vers 384-321 av. J.-C.), tandis que Chrysippe de\nSoli (vers 280-205 av. J.-C.), de l’école stoïcienne, a déﬁni les connecteurs\nlogiques, les axiomes et les règles fondamentales de la logique proposition-\nnelle.",
  "54": "La naissance de la logique mathématique moderne remonte à George\nBoole (1815-1864), qui a publié en 1847 une méthode permettant de décrire\nla théorie des syllogismes aristotéliciens et de la logique propositionnelle\nsous la forme d’équations algébriques, et a proposé une procédure méca-\nnique pour leur résolution.",
  "55": "Gottlob Frege (1848-1925) a été le premier à\ndévelopper un système d’axiomes et de règles pour la logique du premier\nordre, dépassant ainsi les limites imposées par les syllogismes et la logique\npropositionnelle. En 1965, John Robinson a publié la méthode de résolution, qui permet\nune automatisation efﬁcace de l’inférence déductive en logique du premier\nordre.",
  "56": "La programmation logique s’appuie sur cette méthode, et notamment\nsur le langage Prolog (PROgramming in LOGic), dont les bases ont été\nposées par des chercheurs des universités d’Édimbourg et de Marseille au1.2. IA symbolique ix\ndébut des années 1970.",
  "57": "En particulier, Robert Kowalski, à Édimbourg, a\ntravaillé à la déﬁnition des fondements théoriques de la programmation\nlogique, et a proposé une interprétation procédurale des formules logiques\nqui permet de réduire le processus de preuve d’un théorème à un processus\nde calcul sur un ordinateur traditionnel. Alain Colmerauer, à Marseille, a\nété le premier à créer un interprète pour le langage Prolog en 1972.",
  "58": "En logique propositionnelle, les unités élémentaires sont des proposi-\ntions atomiques, c’est-à-dire des énoncés qui ne peuvent être décomposés\ndavantage et qui peuvent être vrais ou faux. Les propositions arbitraires ou\nformules propositionnelles sont obtenues à partir de formules atomiques\nen les combinant à l’aide de connecteurs logiques : négation, conjonction,\ndisjonction et implication. En logique du premier ordre , les formules atomiques se distinguent\nde celles la logique propositionnelle",
  "59": "car elles peuvent avoir un ou plusieurs\narguments. Les arguments sont des termes, c’est-à-dire des représenta-\ntions d’un individu dans le domaine du discours. Dans les cas les plus\nsimples, les termes sont variables s’ils indiquent un individu non spéciﬁé,\nou constants s’ils déterminent un individu spéciﬁque.",
  "60": "Dans ce qui suit,\nnous utiliserons la convention Prolog qui consiste à utiliser des mots com-\nmençant par des lettres minuscules pour désigner les constantes, et des\nmots commençant par des lettres majuscules pour désigner les variables. Les propositions deviennent des prédicats et expriment les propriétés de\nleurs arguments.",
  "61": "Par exemple, p(a)exprime le fait que \"l’individu aestp\"\nou \"l’individu aa la propriété p\" etq(a,b)exprime le fait que \"le couple\nd’individus aetbestq\" ou \"le couple aetba la propriété q\", c’est-à-dire que\n\"aetbsont liés par la relation q\".",
  "62": "Des exemples de formules atomiques en\nlogique propositionnelle sont man(socrates ), qui signiﬁe que \"Socrate est\nun homme\", et fa t h e r (paul ,peter ), qui indique que Paul et Pierre sont liés\npar la relation father , c’est\n-\ntions d’un individu dans le domaine du discours. Dans les cas les plus\nsimples, les termes sont variables s’ils indiquent un individu non spéciﬁé,\nou constants s’ils déterminent un individu spéciﬁque.",
  "63": "Dans ce qui suit,\nnous utiliserons la convention Prolog qui consiste à utiliser des mots com-\nmençant par des lettres minuscules pour désigner les constantes, et des\nmots commençant par des lettres majuscules pour désigner les variables. Les propositions deviennent des prédicats et expriment les propriétés de\nleurs arguments.",
  "64": "Par exemple, p(a)exprime le fait que \"l’individu aestp\"\nou \"l’individu aa la propriété p\" etq(a,b)exprime le fait que \"le couple\nd’individus aetbestq\" ou \"le couple aetba la propriété q\", c’est-à-dire que\n\"aetbsont liés par la relation q\".",
  "65": "Des exemples de formules atomiques en\nlogique propositionnelle sont man(socrates ), qui signiﬁe que \"Socrate est\nun homme\", et fa t h e r (paul ,peter ), qui indique que Paul et Pierre sont liés\npar la relation father , c’est-à-dire que Paul est le père de Pierre. Les formules\natomiques en logique du premier ordre peuvent être combinées avec les\nmêmes connecteurs logiques qu’en logique propositionnelle. En outre, de\nnouvelles formules peuvent être obtenues en utilisant les quantiﬁcateurs\n(9et8).",
  "66": "Les systèmes experts ont été développés dans de nombreux domaines. Le premier et peut-être le plus connu est Mycin, créé dans les années\n1970 à l’université de Stanford par Edward Shortliffe. Son objectif était\nde diagnostiquer les maladies infectieuses du sang et de recommander\ndes antibiotiques, dont la posologie était adaptée au poids du patient. Le\nsystème a bien fonctionné, mais n’a jamais été utilisé en raison de problèmes\njuridiques.x Chapitre 1. IA et modèles génératifs",
  "67": "Voici quelques domaines dans lesquels les systèmes experts peuvent\nêtre utilisés :\n—le diagnostic, qui consiste à tenter de détecter une maladie chez\nun être humain ou un dysfonctionnement d’une machine sur la\nbase de symptômes, c’est-à-dire de manifestations observables de\nla maladie ou du dysfonctionnement;\n—la surveillance, dont l’objectif est de garder un processus sous\ncontrôle en recueillant des informations et en faisant des estima-\ntions sur son déroulement;\n—la planiﬁcation, qui vise à atteindre un certain objectif avec les\nressources disponibles;\n—l’interprétation des informations et des signaux, dont le but est\nd’identiﬁer l’occurrence de situations particulières d’intérêt dans\nles données d’entrée.",
  "68": "Le développement d’un système expert nécessite l’écriture de règles\ngénérales sur le domaine, qui doivent être recueillies en interrogeant un ex-\npert du domaine. Ce processus, connu sous le nom d’extraction de connais-\nsances, s’est avéré extrêmement long et difﬁcile. Aﬁn de l’automatiser, il\nest possible d’utiliser l’apprentissage automatique, abordé dans la section\nsuivante.\n1.2.3",
  "69": "Apprentissage automatique\nEn 1984, Simon a donné la déﬁnition suivante de l’apprentissage [ 22]:\n\"L’apprentissage consiste en des changements dans le système qui sont\nadaptatifs, dans le sens où ils permettent au système d’exécuter la même\ntâche ou des tâches tirées de la même population de manière plus efﬁcace et\nefﬁciente la prochaine fois\". Il est certain que pour fabriquer des machines\nque l’on peut qualiﬁer d’intelligentes, il est nécessaire",
  "70": "de leur donner la\ncapacité d’étendre leurs connaissances et leurs compétences de manière\nautonome. Les deux principales utilisations de l’apprentissage automatique\n\n données d’entrée. Le développement d’un système expert nécessite l’écriture de règles\ngénérales sur le domaine, qui doivent être recueillies en interrogeant un ex-\npert du domaine. Ce processus, connu sous le nom d’extraction de connais-\nsances, s’est avéré extrêmement long et difﬁcile.",
  "71": "Aﬁn de l’automatiser, il\nest possible d’utiliser l’apprentissage automatique, abordé dans la section\nsuivante.\n1.2.3 Apprentissage automatique\nEn 1984, Simon a donné la déﬁnition suivante de l’apprentissage [ 22]:\n\"L’apprentissage consiste en des changements dans le système qui sont\nadaptatifs, dans le sens où ils permettent au système d’exécuter la même\ntâche ou des tâches tirées de la même population de manière plus efﬁcace et\nefﬁciente la prochaine fois\".",
  "72": "Il est certain que pour fabriquer des machines\nque l’on peut qualiﬁer d’intelligentes, il est nécessaire de leur donner la\ncapacité d’étendre leurs connaissances et leurs compétences de manière\nautonome. Les deux principales utilisations de l’apprentissage automatique\nsont l’extraction de connaissances et l’amélioration des performances d’une\nmachine.",
  "73": "Les connaissances extraites peuvent ensuite être utilisées par une\nmachine comme base de connaissances d’un système expert, ou par des\nhumains, par exemple dans le cas de la découverte de nouvelles théories\nscientiﬁques. L’amélioration des performances d’une machine passe, par\nexemple, par l’augmentation des capacités perceptives et motrices d’un\nrobot.\nComme les techniques d’IA en général, les techniques d’apprentis-\nsage peuvent être divisées en techniques symboliques et sous-symboliques.1.3.",
  "74": "IA sub-symbolique xi",
  "75": "La technique la plus intéressante de l’apprentissage symbolique est l’ap-\nprentissage inductif : le système part de faits et d’observations provenant\nd’un instructeur ou de l’environnement, et les généralise pour obtenir des\nconnaissances qui, espérons-le, sont également valables pour des cas non\nencore observés (induction).\nDans l’apprentissage inductif par les exemples, l’enseignant fournit\nun ensemble d’exemples et de contre-exemples d’un concept, et le but est\nde déduire une description du concept lui-même.",
  "76": "Un exemple consiste en\nla description d’une instance du domaine du discours et d’une étiquette;\ncette dernière peut être +si l’instance appartient au concept à apprendre,\nou\u0000si l’instance n’y appartient pas (contre-exemple). Dans le premier cas,\non parle d’une instance appartenant à la classe positive et dans le second\nd’une instance appartenant à la classe négative. Un concept n’est donc\nrien d’autre qu’",
  "77": "un sous-ensemble de l’ensemble de toutes les instances\npossibles du domaine de discours, ou univers. L’ensemble d’exemples et\nde contre-exemples fournis par l’enseignant est appelé jeu d’apprentissage. La description du concept à apprendre doit être telle qu’elle puisse être\nutilisée pour décider si une nouvelle instance, n’appartenant pas au jeu\nd’apprentissage, appartient ou non au concept.",
  "78": "Les systèmes d’apprentissage, qu’ils soient issus de langages attributs-\nvaleurs ou de programmes logiques, ont eu un large éventail d’applications,\nallant du diagnostic des maladies à la prédiction des relations structure-\nactivité dans la conception des médicaments, en passant par la prédiction\nde la cancérogénicité des substances chimiques.",
  "79": "Avec la quantité croissante\nde données qui sont stockées chaque jour par les entreprises et les organi-\nsations en général, les algorithmes d’apprentissage deviennent de plus en\nplus importants car ils permettent d’extraire de cette masse de données des\ninformations cachées, nouvelles et potentiellement utiles.",
  "80": "C’est ce qu’on\nappelle l’exploration de données, ou l’extraction de connaissances à partir\nde données brutes.\n1.3\nensemble de l’ensemble de toutes les instances\npossibles du domaine de discours, ou univers. L’ensemble d’exemples et\nde contre-exemples fournis par l’enseignant est appelé jeu d’apprentissage. La description du concept à apprendre doit être telle qu’elle puisse être\nutilisée pour décider si une nouvelle instance, n’appartenant pas au jeu\nd’apprentissage, appartient ou non au concept.",
  "81": "Les systèmes d’apprentissage, qu’ils soient issus de langages attributs-\nvaleurs ou de programmes logiques, ont eu un large éventail d’applications,\nallant du diagnostic des maladies à la prédiction des relations structure-\nactivité dans la conception des médicaments, en passant par la prédiction\nde la cancérogénicité des substances chimiques.",
  "82": "Avec la quantité croissante\nde données qui sont stockées chaque jour par les entreprises et les organi-\nsations en général, les algorithmes d’apprentissage deviennent de plus en\nplus importants car ils permettent d’extraire de cette masse de données des\ninformations cachées, nouvelles et potentiellement utiles.",
  "83": "C’est ce qu’on\nappelle l’exploration de données, ou l’extraction de connaissances à partir\nde données brutes.\n1.3 IA sub-symbolique\nNous allons maintenant nous intéresser à deux techniques subsymbo-\nliques : les réseaux de neurones et les algorithmes génétiques. 1.3.1 Les réseaux de neurones\nL’idée de simuler le fonctionnement du cerveau humain et animal\naﬁn d’obtenir un comportement intelligent précède le développement dexii Chapitre 1. IA et modèles génératifs\n\u0001\u0002W1W2....",
  "84": "Wnx1x2\nxn-1\nFigura 7: Modello del neurone artiﬁciale.3 Tecniche subsimbolicheVedremo ora tre tecniche subsimboliche: le reti neurali, gli algoritmi geneticie l’intelligenza degli sciami.3.1 Reti neuraliL’idea di simulare il funzionamento del cervello umano e animale per ottenerecomportamenti intelligenti risale a prima della realizzazione del computer,in particolare all’articolo del 1943 di McCulloch e Pitts [ MP43] nel quale sipropose un modello matematico del neurone",
  "85": "umano e si mostrò come reticomposte di tali neuroni artiﬁciali fossero in grado di rappresentare complessefunzioni booleane. Il modello del neurone attualmente più di\u0000uso è chiamato neurone sigmoi-dale ed è costituito da una unità con n ingressi numerici e una uscita numerica.",
  "86": "L’uscita è calcolata in funzione degli ingressi nel seguente modo: ciascun in-gressoxiviene moltiplicato per un pesoWi, i prodotti di queste moltiplicazionisono sommati e il risultato viene fornito in ingresso ad una funzione sigmoida-le. Un modello di questo tipo di neurone è rappresentato in Figura 7, insiemeall’aspetto della funzione sigmoidale.",
  "87": "Si noti che nella somma c’è un terminecostante pari a\u0000\u0000che viene assimilato ad un comune ingresso supponendoche l’ingresso sia sempre a -1 e che il peso per quell’ingresso valga i. Questo modello si comporta in maniera simile a un neurone naturale: ov-vero si “ attiva ” quando riceve gli ingressi “giusti” e si “disattiva” in corri-spondenza di ingressi “sbagliati” . Un neurone è attivo quando la sua uscitaè vicina a +1 ed è disattivo quando la sua uscita è vicina a -1.",
  "88": "Quali sianogli ingressi giusti o sbagliati è determinato dai valori dei pesi degli ingressi:valori positivi dei pesi fanno sì che i relativi ingressi tendano a portare il neu-20FIGURE 1.1– Un modèle de neurone artiﬁciel avec une fonction sigmoïde.\nl’ordinateur, en particulier à l’article de 1943 de McCulloch\nato viene fornito in ingresso ad una funzione sigmoida-le. Un modello di questo tipo di neurone è rappresentato in Figura 7, insiemeall’aspetto della funzione sigmoidale.",
  "89": "Si noti che nella somma c’è un terminecostante pari a\u0000\u0000che viene assimilato ad un comune ingresso supponendoche l’ingresso sia sempre a -1 e che il peso per quell’ingresso valga i. Questo modello si comporta in maniera simile a un neurone naturale: ov-vero si “ attiva ” quando riceve gli ingressi “giusti” e si “disattiva” in corri-spondenza di ingressi “sbagliati” . Un neurone è attivo quando la sua uscitaè vicina a +1 ed è disattivo quando la sua uscita è vicina a -1.",
  "90": "Quali sianogli ingressi giusti o sbagliati è determinato dai valori dei pesi degli ingressi:valori positivi dei pesi fanno sì che i relativi ingressi tendano a portare il neu-20FIGURE 1.1–",
  "91": "Un modèle de neurone artiﬁciel avec une fonction sigmoïde.\nl’ordinateur, en particulier à l’article de 1943 de McCulloch et Pitts [ 15]\ndans lequel un modèle mathématique du neurone humain a été proposé et\nil a été montré comment les réseaux composés de tels neurones artiﬁciels\nétaient capables de représenter des fonctions booléennes complexes.",
  "92": "Le modèle de neurone le plus populaire actuellement est appelé neu-\nrone sigmoïde et consiste en une unité avec nentrées numériques et une\nsortie numérique. La sortie est calculée en fonction des entrées de la ma-\nnière suivante : chaque entrée xiest multipliée par un poids Wi, les produits\nde ces multiplications sont additionnés et le résultat est donné en entrée\nd’une fonction sigmoïde. Un modèle de ce type de neurone est présenté en\nFigure 1.1, ainsi que l’aspect de la fonction sigmoïde.",
  "93": "Notons que dans la\nsomme, il y a un terme constant qui est assimilé à une entrée commune en\nsupposant que cette entrée est toujours à \u00001et que le poids de cette entrée\nvaut i. Ce modèle se comporte de la même manière qu’un neurone naturel :\nil est \"activé\" lorsqu’il reçoit les \"bonnes\" entrées et \"désactivé\" lorsqu’il\nreçoit les \"mauvaises\" entrées. Un neurone est actif lorsque sa sortie est\nproche de +1et inactif lorsque sa sortie est proche de \u00001.",
  "94": "Les valeurs des\npoids d’entrée déterminent quelles entrées sont bonnes ou mauvaises : des\nvaleurs positives des poids font que les entrées relatives tendent à conduire\nle neurone vers l’activation et des valeurs négatives vers la désactivation, et\nvice versa dans le cas de poids négatifs.",
  "95": "Les neurones sont ensuite connec-\ntés les uns aux autres dans des réseaux, de sorte que la sortie d’un neurone\npeut être l’entrée d’autres neurones et que son activation affecte l’activation\ndes neurones en aval. Le neurone sigmoïde dérive du perceptron proposé\nen 1962 par Rosen-Blatt : il en diffère car au lieu d’une fonction sigmoïde,\nle perceptron a une fonction à pas, c’est-à-dire une fonction qui vaut 0\npour les valeurs inférieures à 0 et 1 pour les valeurs supérieures ou égales1.3.",
  "96": "IA sub-symbolique xiii\nà0. Un seul neurone sigmoïde est capable de représenter une certaine\nclasse de concepts en fonction de ses poids : en particulier, il est capable\nde représenter les concepts dans lesquels les exemples sont séparés des\ncontre-exemples par un hyperplan (en imaginant de considérer l’espace\ndes entrées comme un espace euclidien).",
  "97": "Puis ils isolent dans l’espace des\nentrées un demi-espace, c’est-à-dire une région délimitée par un hyperplan\n(dans le\n des valeurs négatives vers la désactivation, et\nvice versa dans le cas de poids négatifs. Les neurones sont ensuite connec-\ntés les uns aux autres dans des réseaux, de sorte que la sortie d’un neurone\npeut être l’entrée d’autres neurones et que son activation affecte l’activation\ndes neurones en aval.",
  "98": "Le neurone sigmoïde dérive du perceptron proposé\nen 1962 par Rosen-Blatt : il en diffère car au lieu d’une fonction sigmoïde,\nle perceptron a une fonction à pas, c’est-à-dire une fonction qui vaut 0\npour les valeurs inférieures à 0 et 1 pour les valeurs supérieures ou égales1.3. IA sub-symbolique xiii\nà0.",
  "99": "Un seul neurone sigmoïde est capable de représenter une certaine\nclasse de concepts en fonction de ses poids : en particulier, il est capable\nde représenter les concepts dans lesquels les exemples sont séparés des\ncontre-exemples par un hyperplan (en imaginant de considérer l’espace\ndes entrées comme un espace euclidien). Puis ils isolent dans l’espace des\nentrées un demi-espace, c’est-à-dire une région délimitée par un hyperplan\n(dans le cas de deux entrées, il s’agit d’une droite).",
  "100": "Aﬁn de représenter des\nconcepts plus complexes, il est nécessaire de composer les neurones en\nréseaux. Les réseaux les plus simples sont appelés réseaux feedforward et sont\nconstitués de couches de neurones : les entrées sont connectées à la première\ncouche de neurones, les sorties de la première couche de neurones sont\nconnectées aux entrées de la deuxième couche, et ainsi de suite, jusqu’à\natteindre la dernière couche dont les sorties deviennent les sorties du\nréseau.",
  "101": "Les couches de neurones de la première à l’avant-dernière couche\nsont dites \"cachées\". Ainsi, un réseau sigmoidal à une couche cachée pourra\ncorrespondre par exemple à la fonction fq:Rd\u0000!Rqdéﬁnie par\nfq(x)=W1sigmoïde (W0x+b0)+b1, (1.1)\noù les poids du réseau sont les coefﬁcients des matrices W12Rh⇥q,W12\nRd⇥het des vecteurs (dits \"biais\") b02Rh,b12Rq. Le vecteur q=\n(W1,W0,b1,b0)contient tous les poids du réseau. L’entier hcorrespond\nau nombre d’unités cachées.",
  "102": "Plus il sera grand, et plus le réseau pourra\nmodéliser des fonctions complexes.\nMais comment obtenir un réseau qui identiﬁe un concept? Contraire-\nment aux systèmes basés sur la connaissance, dans les réseaux neuronaux,\nle choix des poids à la main serait trop complexe. Pour cela, des algorithmes\nd’apprentissage sont utilisés.",
  "103": "Dans ce cas également, nous disposons d’un\nensemble d’apprentissage, qui contient un ensemble de paires (entrées,\nsorties), à la différence que les entrées sont toutes continues, que les sorties\npeuvent être multiples et qu’elles sont également continues, c’est-à-dire\nqu’elles ne sont pas des + ou des - mais des nombres réels (comme par\nexemple dans l’équation (1.1)).",
  "104": "Dans ce cas, on recherche la valeur des\npoids pour laquelle une certaine fonction de l’erreur sur l’ensemble d’ap-\nprentissage est minimale, c’est-à-dire une fonction des différences entre\nles sorties de l’ensemble d’apprentissage et celles du réseau lorsque les\nvaleurs de la paire sont fournies en entrée. La fonction la plus utilisée est\nla somme des erreurs quadratiques.",
  "105": "Comme on le verra dans la section\nsuivante, quand on dispose d’un modèle probabiliste, la fonction d’erreur\nchoisie est l’opposé de la vraisemblance du modèle.xiv Chapitre 1. IA et modèles génératifs L’algorithme le plus largement utilisé pour l’apprentissage dans les\nréseaux neurona\nissage sont utilisés.",
  "106": "Dans ce cas également, nous disposons d’un\nensemble d’apprentissage, qui contient un ensemble de paires (entrées,\nsorties), à la différence que les entrées sont toutes continues, que les sorties\npeuvent être multiples et qu’elles sont également continues, c’est-à-dire\nqu’elles ne sont pas des + ou des - mais des nombres réels (comme par\nexemple dans l’équation (1.1)).",
  "107": "Dans ce cas, on recherche la valeur des\npoids pour laquelle une certaine fonction de l’erreur sur l’ensemble d’ap-\nprentissage est minimale, c’est-à-dire une fonction des différences entre\nles sorties de l’ensemble d’apprentissage et celles du réseau lorsque les\nvaleurs de la paire sont fournies en entrée. La fonction la plus utilisée est\nla somme des erreurs quadratiques.",
  "108": "Comme on le verra dans la section\nsuivante, quand on dispose d’un modèle probabiliste, la fonction d’erreur\nchoisie est l’opposé de la vraisemblance du modèle.xiv Chapitre 1. IA et modèles génératifs L’algorithme le plus largement utilisé pour l’apprentissage dans les\nréseaux neuronaux multicouches est appelé rétropropagation ( backpropaga-\ntion). Le nom de \"backpropagation\" et a été proposé par Rumelhart, Hinton\net Williams en 1986.",
  "109": "Elle consiste à calculer l’erreur de la couche de sortie du\nréseau sur chaque exemple et à la propager en arrière vers les neurones des\ncouches cachées. Sur la base de l’erreur propagée, les poids des neurones\nsont ensuite mis à jour. Si, après avoir considéré tous les exemples de cette\nmanière, l’erreur est tombée en dessous d’un seuil prédéﬁni, on s’arrête,\nsinon tous les exemples de l’ensemble d’apprentissage sont considérés à\nnouveau.",
  "110": "Les réseaux multicouches profonds ont connu un grand succès et ont\nété appliqués dans de nombreux domaines, notamment la vision par ordi-\nnateur, la reconnaissance vocale, la traduction automatique, la bioinforma-\ntique, la conception de médicaments et l’analyse d’images médicales. Dans\nle domaine de la vision par ordinateur, par exemple, ils ont été capables de\nreconnaître des caractères manuscrits, de reconnaître des objets dans des\nimages et des vidéos et de classer des images.",
  "111": "Ces résultats ont été obtenus\nà l’aide d’un type particulier de réseau neuronal appelé \"convolutif\". Dans\nce réseau, certaines couches appliquent une opération de convolution à\nl’entrée : un ﬁltre est appliqué à l’entrée bidimensionnelle pour produire\nune image ﬁltrée.",
  "112": "Ces ﬁltres, qui sont entraînés conjointement avec les\nparamètres des couches traditionnelles, identiﬁent des caractéristiques\nde l’image de complexité croissante : par exemple, une première couche\nconvolutive pourrait identiﬁer des bords rectilignes approximatifs dans\nl’image d’entrée, une deuxième couche des combinaisons de bords recti-\nlignes (angles) et ainsi de suite, jusqu’à identiﬁer les caractéristiques de\nl’image qui servent à la classer.",
  "113": "1.3.2 Les algorithmes génétiques\nAlors que les réseaux neuronaux s’inspirent du cerveau humain pour\nproduire un comportement intelligent, les algorithmes génétiques s’ins-\npirent de la théorie de l’évolution.",
  "114": "Il s’agit d’algorithmes de recherche dans\nl’espace des états, dans lequel un état est considéré comme un individu, au\nsein d’une population d’individus qui est amené à évoluer selon les lois de\nl’évolutionnisme aﬁn d’obtenir des états qui sont de bonnes solutions au\nproblème.\nPour appliquer un algorithme génétique, il est nécessaire de représen-\nter l’état comme une séquence de symboles\n les\nparamètres des couches traditionnelles, identiﬁent des caractéristiques\nde l’image de complexité croissante : par exemple, une première couche\nconvolutive pourrait identiﬁer des bords rectilignes approximatifs dans\nl’image d’entrée, une deuxième couche des combinaisons de bords recti-\nlignes (angles) et ainsi de suite, jusqu’à identiﬁer les caractéristiques de\nl’image qui servent à la classer.",
  "115": "1.3.2 Les algorithmes génétiques\nAlors que les réseaux neuronaux s’inspirent du cerveau humain pour\nproduire un comportement intelligent, les algorithmes génétiques s’ins-\npirent de la théorie de l’évolution.",
  "116": "Il s’agit d’algorithmes de recherche dans\nl’espace des états, dans lequel un état est considéré comme un individu, au\nsein d’une population d’individus qui est amené à évoluer selon les lois de\nl’évolutionnisme aﬁn d’obtenir des états qui sont de bonnes solutions au\nproblème.\nPour appliquer un algorithme génétique, il est nécessaire de représen-\nter l’état comme une séquence de symboles (dans le cas le plus fréquent\nune séquence de bits), qui représente le patrimoine génétique (ou géno-\ntype) d’un individu et le caractérise complètement.",
  "117": "Il est alors nécessaire1.3. IA sub-symbolique xv\nde disposer d’une fonction d’aptitude qui, compte tenu d’une séquence de\nsymboles, indique le degré d’aptitude de l’individu, c’est-à-dire sa capacité\nà survivre dans son environnement. Dans le cas d’un algorithme génétique,\nla fonction de ﬁtness représente la proximité de l’état par rapport à une\nsolution ou sa qualité en tant que solution. Un algorithme génétique commence avec une population initiale d’in-\ndividus générés aléatoirement.",
  "118": "Il exécute ensuite un cycle qui se termine\nlorsque la ﬁtness du meilleur individu dépasse un certain seuil, c’est-à-dire\nlorsque la population contient une solution sufﬁsamment bonne. À chaque\nétape du cycle, une nouvelle population est générée à l’aide des opérateurs\nde sélection, de croisement et de mutation. En pratique, chaque itération du\ncycle correspond à une génération.",
  "119": "La nouvelle population est générée en\nsélectionnant des paires d’individus au hasard, mais avec une probabilité\nqui dépend de leur aptitude : les individus ayant une meilleure aptitude\nont plus de chances d’être sélectionnés.",
  "120": "Ensuite, on applique l’opérateur\nde croisement qui, étant donné le couple d’individus, en produit un autre,\nobtenu en \"mélangeant\" le patrimoine génétique de différentes manières :\ndans le cas de génotypes présentés comme des séquences de bits de lon-\ngueur ﬁxe n, l’opérateur de croisement le plus simple choisit un nombre\nentier aléatoire iinférieur à net copie dans le premier descendant les pre-\nmiers bits du premier parent et les derniers n\u00001bits du second parent,\ntandis que dans le second descendant il copie l’inverse.",
  "121": "Les descendants ainsi obtenus sont ensuite soumis à une mutation,\ndans laquelle de petites modiﬁcations du génotype sont apportées au ha-\nsard. Le processus de sélection, de croisement et de mutation est répété\njusqu’à l’obtention d’une nouvelle population de taille ﬁxe. La ﬁtness de\ntous les individus de la nouvelle population est ensuite calculée. Il existe\nde nombreuses variantes de ce type d’algorithme.",
  "122": "Par exemple, dans cer-\ntains, une partie de l’ancienne population est transférée directement dans la\nnouvelle, en utilisant la sélection. Les algorithmes génétiques peuvent éga-\nlement être utilisés pour effectuer des tâches d’apprentissage automatique.",
  "123": "Dans ce cas, il est nécessaire de représenter les descriptions du concept à\napprend\n génétique de différentes manières :\ndans le cas de génotypes présentés comme des séquences de bits de lon-\ngueur ﬁxe n, l’opérateur de croisement le plus simple choisit un nombre\nentier aléatoire iinférieur à net copie dans le premier descendant les pre-\nmiers bits du premier parent et les derniers n\u00001bits du second parent,\ntandis que dans le second descendant il copie l’inverse.",
  "124": "Les descendants ainsi obtenus sont ensuite soumis à une mutation,\ndans laquelle de petites modiﬁcations du génotype sont apportées au ha-\nsard. Le processus de sélection, de croisement et de mutation est répété\njusqu’à l’obtention d’une nouvelle population de taille ﬁxe. La ﬁtness de\ntous les individus de la nouvelle population est ensuite calculée. Il existe\nde nombreuses variantes de ce type d’algorithme.",
  "125": "Par exemple, dans cer-\ntains, une partie de l’ancienne population est transférée directement dans la\nnouvelle, en utilisant la sélection. Les algorithmes génétiques peuvent éga-\nlement être utilisés pour effectuer des tâches d’apprentissage automatique.",
  "126": "Dans ce cas, il est nécessaire de représenter les descriptions du concept à\napprendre comme une séquence de symboles : l’aptitude sera donnée par\nla précision avec laquelle une description du concept classe les exemples\nde l’ensemble d’apprentissage. Les algorithmes génétiques ont eu de nombreuses applications en\nbiologie, en ingénierie et dans les sciences physiques et sociales.",
  "127": "L’une des\nplus intéressantes est la programmation automatique, c’est-à-dire la généra-\ntion automatique de programmes informatiques pour résoudre un certain\nproblème. Dans ce cas, le génotype des individus est constitué d’arbres re-\nprésentant un seul programme dans un langage de programmation donné.xvi Chapitre 1. IA et modèles génératifs\nL’opérateur de croisement consiste à remplacer un sous-arbre d’un parent\npar un sous-arbre de l’autre parent.",
  "128": "La fonction de ﬁtness est calculée en\nexécutant le programme sur un ensemble de données d’entrée.\n1.4 Modèles génératifs et apprentissage statistique\nLa tâche générale de l’apprentissage statistique est d’apprendre un\nobjet mathématique (par exemple une fonction permettant de réaliser des\nprédictions) à partir d’une base de données dite d’entraînement ou d’ap-\nprentissage. Voici quelques exemples :\n—en apprentissage supervisé",
  "129": ", il s’agit d’apprendre une fonction per-\nmettant de prédire la valeur d’une réponse y(par exemple la sévé-\nrité d’une maladie) à partir de données x(par exemple une image\nmédicale);\n—en classiﬁcation non-supervisée (aussi appelée clustering ) , il s’agit\nd’apprendre une partition de l’espace dans lequel vivent les don-\nnées, aﬁn de pouvoir les grouper en classes homogènes;",
  "130": "—en apprentissage par renforcement, il s’agit d’apprendre une fonc-\ntion qui à chaque situation préconise une action à entreprendre\n(par exemple dans le cas d’un algorithme de jeu d’échecs). Dans tous ces cadres, les fonctions à apprendre dépendent de la loi de pro-\nbabilité (inconnue) des données observées. Une approche générale serait\ndonc d’apprendre dans un premier temps cette loi de probabilité, puis de\nl’utiliser aﬁn de résoudre le problème spéciﬁque qui nous intéresse.",
  "131": "La\ntâche générale d’apprentissage d’une loi de probabilités à partir de données\nest un des problèmes fondamentaux des statistiques, souvent appelé esti-\nmation de densité . L’un des avantages de cette approche est qu’elle permet\nsouvent d’être capable de générer de nouvelles \"fausses\" données après\nla phase d’apprentissage, c’est pourquoi l’on parle de modèles génératifs .",
  "132": "La génération de nouvelles données sythétiques est en effet utile dans de\n il s’agit\nd’apprendre une partition de l’espace dans lequel vivent les don-\nnées, aﬁn de pouvoir les grouper en classes homogènes; —en apprentissage par renforcement, il s’agit d’apprendre une fonc-\ntion qui à chaque situation préconise une action à entreprendre\n(par exemple dans le cas d’un algorithme de jeu d’échecs).",
  "133": "Dans tous ces cadres, les fonctions à apprendre dépendent de la loi de pro-\nbabilité (inconnue) des données observées. Une approche générale serait\ndonc d’apprendre dans un premier temps cette loi de probabilité, puis de\nl’utiliser aﬁn de résoudre le problème spéciﬁque qui nous intéresse. La\ntâche générale d’apprentissage d’une loi de probabilités à partir de données\nest un des problèmes fondamentaux des statistiques, souvent appelé esti-\nmation de densité .",
  "134": "L’un des avantages de cette approche est qu’elle permet\nsouvent d’être capable de générer de nouvelles \"fausses\" données après\nla phase d’apprentissage, c’est pourquoi l’on parle de modèles génératifs .",
  "135": "La génération de nouvelles données sythétiques est en effet utile dans de\nnombreux cadres :\n—elle peut nous permettre de juger si le modèle que l’on a appris\nest bon : en effet, si les nouvelles données sont très différentes\nde la base de données originales, cela falsiﬁera le modèle et nous\nencouragera à l’améliorer;\n—dans certains cas applicatifs, la génération de nouvelles données\nest un objectif en soi (par exemple, la génération de nouvelles\nmolécules en médecine [10]);\n—si certaines données sont incomplètes, un modèle génératif peut\npermettre des les compléter (voir par exemple [13]).1.4.",
  "136": "Modèles génératifs et apprentissage statistique xvii\nEn guise d’exemple ﬁl rouge, nous nous baserons sur une base de don-\nnées très classique appelée MNIST1. MNIST est constituée de 60000 images\nde chiffres calligraphiés de 28⇥28pixels. Pour simpliﬁer, on considèrera\nune version binarisée de ces images, où chaque pixel ne peut prendre que\nles valeurs 0ou1. Les données vivent donc dans {0,1}28⇥28, et suivront\ndonc une loi inconnue sur cet espace discret.",
  "137": "Quelques numéros de cette\nbase de données sont montrés sur la Figure 1.2. 1.4.1 Apprentissage par maximum de vraisemblance On suppose avoir affaire à des données x1,...,xn2XoùXest un\nespace équipé d’une mesure de référence (par exemple la mesure de Le-\nbesgue si les données sont continues, ou la mesure de comptage si elles\nsont discrètes, comme dans notre exemple ﬁl rouge).",
  "138": "On suppose que ces\nx1,...,xnsont autant de réalisations indépendantes et indentiquement dis-\ntribuées (i.i.d.) d’une variable aléatoire X, admettant une densité pdonnées\nvis-à-vis de notre mesure de référence. La densité pdonnées est inconnue, et\nnous souhaitons l’approximer à l’aide d’un modèle paramétrique , à savoir une\nfamille de densités (pq)q2Q, indexée par un ensemble appelé ensemble des\nparamètres (généralement inclus dans un espace vectoriel de dimension\nﬁnie).",
  "139": "L’idée serait donc d’utiliser nos données aﬁn de trouver un bq2Qtel\nquepbq⇡pdonnées . Cette tâche, généralement appelée estimation statistique ,\npeut être effectuée de bien des manières, selon le choix du sens que l’on\nsouhaite donner à l’assertion \" pbq⇡pdonnées \". Nous allons nous concentrer\nici sur l’exemple le plus connu de technique d’estimation, à savoir l’esti-\nmation par maximum de vraisemblance , introduite par Fisher au début du\nsiècle dernier.",
  "140": "Parmi les méthodes concurrent\n notre exemple ﬁl rouge). On suppose que ces\nx1,...,xnsont autant de réalisations indépendantes et indentiquement dis-\ntribuées (i.i.d.) d’une variable aléatoire X, admettant une densité pdonnées\nvis-à-vis de notre mesure de référence.",
  "141": "La densité pdonnées est inconnue, et\nnous souhaitons l’approximer à l’aide d’un modèle paramétrique , à savoir une\nfamille de densités (pq)q2Q, indexée par un ensemble appelé ensemble des\nparamètres (généralement inclus dans un espace vectoriel de dimension\nﬁnie). L’idée serait donc d’utiliser nos données aﬁn de trouver un bq2Qtel\nquepbq⇡pdonnées .",
  "142": "Cette tâche, généralement appelée estimation statistique ,\npeut être effectuée de bien des manières, selon le choix du sens que l’on\nsouhaite donner à l’assertion \" pbq⇡pdonnées \". Nous allons nous concentrer\nici sur l’exemple le plus connu de technique d’estimation, à savoir l’esti-\nmation par maximum de vraisemblance , introduite par Fisher au début du\nsiècle dernier.",
  "143": "Parmi les méthodes concurrentes, les méthodes bayésiennes\n(détaillées par exemple dans le livres de Robert [ 19]) sont historiquement\nles plus importantes.\nLa question principale permettant d’établir une technique d’inférence\nest donc : \"quel sens donner à pbq⇡pdonnées ?\". Une idée naturelle serait de\nse donner une distance dsur l’ensemble des densités, puis de choisir\nbq2argminq2Qd(pq,pdonnées ).",
  "144": "(1.2)\nCette idée se heurte à un écueil important : nous ne connaissons pas\npdonnées , donc nous ne pourrons certainement pas minimiser la fonction\nq7!d(pbq,pdonnées ). En revanche, nous avons accès à ntirages i.i.d. de\npdonnées : notre jeu de données x1,...,xn. Tout le jeu va consister à trouver\n1. http ://yann.lecun.com/exdb/mnist/xviii Chapitre 1. IA et modèles génératifs\nun moyen d’utiliser ces données pour résoudre approximativement le pro-\nblème (1.2).",
  "145": "C’est ici que le choix de la distance peut faire toute la différence :\npour certaines distances, les choses seront en effet plus simples que pour\nd’autres. Le maximum de vraisemblance correspond à une notion distance\nissue de la théorie de l’information : la divergence de Kullback-Leibler . Déﬁnition 1.4.1. Soient p1etp2deux densités sur Xtelles que le support de p1\nest inclus dans le support de p2.",
  "146": "La divergence de Kullback-Leibler entre p1etp2\nest la quantité\nKL(p1,p2)=Z\nXlog✓p1(x)\np2(x)◆\np1(x)dx=EX⇠p1\nlog✓p1(X)\np2(X)◆\u0000\n. (1.3)\nMalheureusement, la divergence de Kullback-Leibler n’est pas une\nvéritable distance sur l’espace des densités. En effet, l’axiome de symétrie\nest violé car on n’a pas, en général, KL(p1,p2)= KL(p2,p1). le cas gaussien,\npour lequel la divergence a une forme explicite, produit déjà un exemple\nde cette asymmétrie.\nProposition 1.4.2.",
  "147": "Pour tous µ1,µ22R, ets1,s2, on a\nKL(N(µ1,s1),N(µ2,s2)) = logs2\ns1+s2\n1+(µ1\u0000µ2)2\n2s2\n2\u00001\n2. (1.4)\nSi elle n’est pas une distance, la divergence de Kullback-Leibler pos-\nsède tout de même un certain nombre de bonnes propriétés, résumées dans\nla proposition suivante.\nProposition 1.4.3. Soient p1etp2deux densités sur Xtelles que le\n(p1,p2)=Z\nXlog✓p1(x)\np2(x)◆\np1(x)dx=EX⇠p1\nlog✓p1(X)\np2(X)◆\u0000\n.",
  "148": "(1.3)\nMalheureusement, la divergence de Kullback-Leibler n’est pas une\nvéritable distance sur l’espace des densités. En effet, l’axiome de symétrie\nest violé car on n’a pas, en général, KL(p1,p2)= KL(p2,p1). le cas gaussien,\npour lequel la divergence a une forme explicite, produit déjà un exemple\nde cette asymmétrie.\nProposition 1.4.2. Pour tous µ1,µ22R, ets1,s2, on a\nKL(N(µ1,s1),N(µ2,s2)) = logs2\ns1+s2\n1+(µ1\u0000µ2)2\n2s2\n2\u00001\n2.",
  "149": "(1.4)\nSi elle n’est pas une distance, la divergence de Kullback-Leibler pos-\nsède tout de même un certain nombre de bonnes propriétés, résumées dans\nla proposition suivante.\nProposition 1.4.3. Soient p1etp2deux densités sur Xtelles que le support de\np1est inclus dans le support de p 2. On a\n1.KL(p1,p2)>0,\n2.KL(p1,p2)= 0()p1=p2.",
  "150": "Ces bonnes propriétés étant essentiellement des conséquences de l’in-\négalité de Jensen, il parait naturel de se dire que l’on pourrait remplacer la\nfonction logarithme par une autre fonction convexe. Ce type de généralisa-\ntion est à la base de la notion de f-divergences. Cependant, le logarithme\ndispose d’une autre qualité qui sera (comme on va bientôt le voir) fon-\ndamentale : sa propriété de morphisme vis-à-vis de l’addition et de la\nmultiplication.",
  "151": "Cette propriété explique la place centrale tenue par la di-\nvergence de Kullback-Leibler au sein des (pseudo)distances entre lois de\nprobabilités.1.4. Modèles génératifs et apprentissage statistique xix\nRevenons à notre problème d’ estimation statistique. On s’intéresse\nà minimiser KL(pdonnées ,pq).",
  "152": "En utilisant la propriété de morphisme du\nlogarithme, on peut réécrire\nKL(pdonnées ,pq)=EX⇠pdonnées\nlog✓pdonnées (X)\npq(X)◆\u0000\n(1.5)\n=EX⇠pdonnées [logpdonnées (X)]\u0000EX⇠pdonnées [logpq(X)].\n(1.6)\nOn remarque alors que le premier terme de cette somme ne dépend pas de\nq, par conséquent\nargminq2QKL(pdonnées ,pq)=argmaxq2QEX⇠pdonnées [ logpq(X)]. (1.7)\nLes choses ont alors été considérablement simpliﬁées. En effet, on peut utili-\nser notre jeu de données pour approcher l’espérance EX⇠",
  "153": "pdonnées [logpq(X)]\npar Monte Carlo :\nEX⇠pdonnées [ logpq(X)]⇡1\nnn\nÂ\ni=1logpq(xi) . (1.8)\nLes données étant supposées être des réalisations i.i.d. de densité pdonnées , la\nloi des grands nombres garantira la justesse asymptotique de cette approxi-\nmation. Ce raisonnement motive la déﬁnition de la fonction de vraisemblance\ndes données :\n`:q7!n\nÂ\ni=1logpq(xi). (1.9)\nL’estimateur du maximum de vraisemblance sera alors\nbqMV2argmaxq2Q`(q). (1.10)\nOn aimerait idéalement que bqMVapproche",
  "154": "la solution de (1.2) quand nest\ngrand. La question principale quant à la qualité de l’estimateur du maxi-\nmum de vraisemblance est alors : qu’a-t-on perdu lors de l’approximation\nde Monte Carlo (1.8\nmaxq2QEX⇠ pdonnées [ logpq(X)]. (1.7)\nLes choses ont alors été considérablement simpliﬁées. En effet, on peut utili-\nser notre jeu de données pour approcher l’espérance EX⇠ pdonnées [logpq(X)]\npar Monte Carlo :\nEX⇠pdonnées [ logpq(X)]⇡1\nnn\nÂ\ni=1logpq(xi) .",
  "155": "(1.8)\nLes données étant supposées être des réalisations i.i.d. de densité pdonnées , la\nloi des grands nombres garantira la justesse asymptotique de cette approxi-\nmation. Ce raisonnement motive la déﬁnition de la fonction de vraisemblance\ndes données :\n`:q7!n\nÂ\ni=1logpq(xi). (1.9)\nL’estimateur du maximum de vraisemblance sera alors\nbqMV2argmaxq2Q`(q). (1.10)\nOn aimerait idéalement que bqMVapproche la solution de (1.2) quand nest\ngrand.",
  "156": "La question principale quant à la qualité de l’estimateur du maxi-\nmum de vraisemblance est alors : qu’a-t-on perdu lors de l’approximation\nde Monte Carlo (1.8)? C’est l’objet de la statistique asymptotique, exposée\npar exemple dans le livre classique de Van der Vaart [27].\nAu delà de son interprétation à l’aide de la divergence de Kullback-\nLeibler, la méthode du maximum de vraisemblance peut être justiﬁée par\nle fait qu’on choisit le paramètre qui maximise la probabilité des données.",
  "157": "Cette justiﬁcation est en fait la motivation historique principale de cette\nméthode. Une analyse historique intéressante du développelment du maxi-\nmum de vraisemblance a été réalisée par Stiegler [23].xx Chapitre 1. IA et modèles génératifs 1.5 Modèles profonds à variables latentes La contrainte principale posée par la méthode du maximum de vrai-\nsemblance est la nécessité d’être capable d’évaluer et d’optimiser la densité\ndes données selon notre modèle.",
  "158": "Cela restreint considérablement le choix\ndes modèles probabilistes pouvant être utilisés. Nous allons présenter\nici une famille de modèles n’obéissant pas à cette contrainte (les modèles\nprofonds à variables latentes ). Bien que leur vraisemblance ne soit pas cal-\nculable aisément, ces modèles peuvent être entraînés par maximum de\nvraisemblance approché, via une méthode très générale appelée inférence\nvariationnelle .",
  "159": "On s’intéressera en particulier à une version récente de l’infé-\nrence variationnelle, appelée inférence variationelle par échantillonnage\npréférentiel ( importance weighted variational inference ), introduite par Burda,\nGrosse et Salakhutdinov [2].\n1.5.1 Modèles linéaires à variables latentes\nL’idée générale des modèles à variables latentes est la suivante :",
  "160": "bien\nque les données vivent généralement dans un espace de grande dimension\n(dans le cas d’images en niveaux de gris, la dimension est le nombre de\npixels), on suppose qu’un faible nombre de \"facteurs\" cachés expliquent rai-\nsonnablement bien la diversité des données.",
  "161": "Avant de formaliser ce postulat\nd’existence de facteurs cachés, donnons quelques exemples concrets :\n—si les données sont des images de grains de beauté ou potentiel\nmélanomes, savoir une poignée d’informations clés (la taille de\nla tache, sa rotondité, la couleur de peau, ...) sera sufﬁsant pour\nrésumer l’image sans perte d’information;\n—il en est de même si les données sont des images de visages : dans\nce cas, les facteurs pourraient être la pilosité, la couleur de peau, la\nprésence de lunettes;\n—si les données sont des textes, connaître le thème, le ton et le style\ndu texte peut permettre d’en avoir une idée assez précise.",
  "162": "La variable latente sera généralement vue comme une représent\n1.5.1 Modèles linéaires à variables latentes\nL’idée générale des modèles à variables latentes est la suivante : bien\nque les données vivent généralement dans un espace de grande dimension\n(dans le cas d’images en niveaux de gris, la dimension est le nombre de\npixels), on suppose qu’un faible nombre de \"facteurs\" cachés expliquent rai-\nsonnablement bien la diversité des données.",
  "163": "Avant de formaliser ce postulat\nd’existence de facteurs cachés, donnons quelques exemples concrets :\n—si les données sont des images de grains de beauté ou potentiel\nmélanomes, savoir une poignée d’informations clés (la taille de\nla tache, sa rotondité, la couleur de peau, ...) sera sufﬁsant pour\nrésumer l’image sans perte d’information;\n—il en est de même si les données sont des images de visages : dans\nce cas, les facteurs pourraient être la pilosité, la couleur de peau, la\nprésence de lunettes;\n—si les données sont des textes, connaître le thème, le ton et le style\ndu texte peut permettre d’en avoir une idée assez précise.",
  "164": "La variable latente sera généralement vue comme une représentation synthé-\ntique des données , et vivra à ce titre souvent dans un espace (ou une variété)\nde dimension plus faible que celui des données. On désignera parfois la\nvariable latente sous le nom de code ou de facteurs . Aﬁn de mettre cette idée générale en pratique",
  "165": ", les modèles à variables\nlatentes supposent l’existence de variables aléatoire latentes z2Z, qui\npermettent d’expliquer nos données x2X. On aimerait donc formaliser\nl’idée que \" zexplique x\". Pour ce faire, les modèles à variables latentes\npostuleront que la loi de xsachant zest une loi \"simple\", par exemple une1.5. Modèles profonds à variables latentes xxi\nloi gaussienne (dans le cas de données continues), ou un produit de lois de\nBernoulli (dans le cas de notre exemple ﬁl-rouge).",
  "166": "Analyse factorielle Il s’agit du plus ancien exemple de modèle à variable\nlatente (voir par exemple Jöreskog [ 8]), pour lequel les données sont conti-\nnues ( X=Rd), et expliquées par un code de faible dimension ( Z=Rq\navec q⌧d). Ici, la variable latente et les données sont gaussiennes, et une\nfonction afﬁne z7!Wz+bpermet de les lier :\n⇢z⇠N(0,Id)\nx⇠N(Wz+µ,S).(1.11)",
  "167": "Les paramètres inconnus du modèle sont W2Rd⇥q,µ2Rq, etS2S++\nd,\noùS++\nddésigne le cône des matrices déﬁnies positives de taille q⇥q. Ces\nderniers peuvent être estimés par maximum de vraisemblance. En effet,\nla vraisemblance est aisée à calculer, et peut être maximisée en utilisant\npar exemple une méthode de gradient.",
  "168": "Le modèle d’analyse factorielle a\nune interprétation géométrique simple : les données, bien que de grande\ndimension d, sont proches d’un sous-espace afﬁne de faible dimension\nq⌧d, à savoir l’image de Rdpar la fonction z7!Wz+b. Le cas particulier\noùSest proportionnelle à l’identité a été étudié en détail par Tipping et\nBishop [ 25], qui ont appelé ce modèle particulier analyse en composantes\nprincipales probabiliste (ACPP) .",
  "169": "Pour l’ACPP, le maximum de vraisemblance\nde tous les paramètres peut être obtenu directement en effectuant une\ndécomposition en valeurs singulières de la matrice des données, sans avoir\nrecours à un algorithme d’optimisation. Données non-euclidiennes Si l’analyse factorielle et ses variations sont\nadaptées au cas de données vivant dans un espace euclidien Rd, il n’est\npas conceptuellement dif\n positives de taille q⇥q. Ces\nderniers peuvent être estimés par maximum de vraisemblance.",
  "170": "En effet,\nla vraisemblance est aisée à calculer, et peut être maximisée en utilisant\npar exemple une méthode de gradient. Le modèle d’analyse factorielle a\nune interprétation géométrique simple : les données, bien que de grande\ndimension d, sont proches d’un sous-espace afﬁne de faible dimension\nq⌧d, à savoir l’image de Rdpar la fonction z7!Wz+b.",
  "171": "Le cas particulier\noùSest proportionnelle à l’identité a été étudié en détail par Tipping et\nBishop [ 25], qui ont appelé ce modèle particulier analyse en composantes\nprincipales probabiliste (ACPP) . Pour l’ACPP, le maximum de vraisemblance\nde tous les paramètres peut être obtenu directement en effectuant une\ndécomposition en valeurs singulières de la matrice des données, sans avoir\nrecours à un algorithme d’optimisation. Données non-euclidiennes",
  "172": "Si l’analyse factorielle et ses variations sont\nadaptées au cas de données vivant dans un espace euclidien Rd, il n’est\npas conceptuellement difﬁcile de les étendre à des cas plus complexes, en\nremplaçant simplement la gaussienne N(Wz+b,S)par une loi adaptée\nà l’espace qui nous intéresse.",
  "173": "Par exemple, si les données sont des vec-\nteurs d’entiers, vivant donc dans Nd, on pourrait remplacer la gaussienne\nmultivariée par un produit de lois de Poisson P, et considérer ainsi le\nmodèle ⇢z⇠N(0,Id)\nx⇠’d\nj=1P(exp([Wz+b]j)).(1.12)\nLa présence de la fonction exponentielle permet de s’assurer que le para-\nmètre de la loi de Poisson sera bien strictement positif. Ce type de modèle\na par exemple été employé par Chiquet, Mariadassou et Robin [ 3] dans\nle cadre de modèles d’écologie microbienne.",
  "174": "Revenons un instant à notrexxii Chapitre 1. IA et modèles génératifs\nexemple ﬁl -rouge des images binarisées. Ici, les données vivent dans un\nensemble discret {0,1}d. Un choix naturel est alors d’utiliser un produit de\nlois de Bernoulli :\n⇢z⇠N(0,Id)\nx⇠’d\nj=1B(sigmoïde ([Wz+b]j)).(1.13)\nIci, la fonction sigmoïde : t7!1/(1\u0000e\u0000t)se charge de contraindre le\nparamètre de la loi de Bernoulli a être bien entre 0et1.",
  "175": "En effet, on a\nsigmoïde (R)= ] 0, 1[.\n(Indé)pendance des variables observées Dans le cas du modèle (1.12)\nadapté aux vecteurs d’entiers comme dans celui des images binaires (1.13) ,\nle fait que la loi de xsachant zsoit modélisée par un produit de lois\nsimples implique que, conditionnellement à z, les coordonnées de xsont\nindépendantes :\nx1??x2??...??xd|z. (1.14)\nEn revanche, si l’on ne conditionne pas à z, lesx1,...,xdne sont plus indé-\npendants!",
  "176": "Cela illustre le fait général que la loi de x|zpeut être très simple,\ntandis que celle de xdemeure complexe. 1.5.2 Modèles profonds à variables latentes\nLes modèles précédents sont limités par le fait que la fonction envoyant\nle code zvers la loi de x|zest essentiellement linéaire. Une généralisation\nnaturelle serait alors de remplacer cette fonction linéaire par une fonction\nplus générale, par exemple paramétrée par un réseau de neurones. Ansi,\nnotre modèle d’ analyse factorielle\n⇢z⇠N(0,Id)",
  "177": "x⇠N(Wz+b,S).(1.15)\nsera remplacé par un modèle du type\n des variables observées Dans le cas du modèle (1.12)\nadapté aux vecteurs d’entiers comme dans celui des images binaires (1.13) ,\nle fait que la loi de xsachant zsoit modélisée par un produit de lois\nsimples implique que, conditionnellement à z, les coordonnées de xsont\nindépendantes :\nx1??x2??...??xd|z. (1.14)\nEn revanche, si l’on ne conditionne pas à z, lesx1,...,xdne sont plus indé-\npendants!",
  "178": "Cela illustre le fait général que la loi de x|zpeut être très simple,\ntandis que celle de xdemeure complexe. 1.5.2 Modèles profonds à variables latentes\nLes modèles précédents sont limités par le fait que la fonction envoyant\nle code zvers la loi de x|zest essentiellement linéaire. Une généralisation\nnaturelle serait alors de remplacer cette fonction linéaire par une fonction\nplus générale, par exemple paramétrée par un réseau de neurones. Ansi,\nnotre modèle d’ analyse factorielle\n⇢z⇠N(0,Id)",
  "179": "x⇠N(Wz+b,S).(1.15)\nsera remplacé par un modèle du type\n⇢z⇠N(0,Id)\nx⇠N(µq(z),Sq(z)),(1.16)\noùµq:Z\u0000 ! RdetSq:Z\u0000 ! S++\ndsont des réseaux de neurones, dont\nles paramètres sont stockés dans le vecteur q2Q.\nPlus généralement, on appellera modèle profond à variables latentes un\nmodèle du type⇢z⇠p\nx⇠F(fq(z)),(1.17)1.5. Modèles profonds à variables latentes xxiii\noùpest une loi de probabilités sur Zappelée loi a priori ,(F(h))h2Eest une\nfamille paramétrée de lois de probabilités sur X, etfq:Z\u0000 !",
  "180": "Eest un\nréseau de neurones paramétré par q2Q. La famille (F(h))h2Eest appelée\nmodèle d’observation et le réseau fqest appelé decodeur ouréseau génératif .\nEn effet, son rôle est de transformer un code zen paramètres du modèle\nd’observation, permettant par là même de générer des échantillons selon\nle modèle. Le fonctionnement général de ce type de modèle est présenté\nﬁgure 1.2.",
  "181": "Ces modèles sont également connus sous le nom d’autoencodeur\nvariationnel, et ont été introduits indépendamment par Rezende, Mohamed\net Wiestra [18] et par Kingma et Welling [ 9]. Vériﬁons rapidement que cette construction générale contient bien\nles modèles linéaires présentés précédemment.",
  "182": "On retrouve bien l’analyse\nfactorielle classique en prenant un a priori gaussien p=N(0,Iq), un mo-\ndèle d’observation gaussien (F(h))h=(N(µ,S))µ,Sainsi qu’un décodeur\nlinéaire fq=(µq,Sq), avec µq(z)= Wz+betSq(z)constante égale à S.\nDans ce cas les paramètres du décodeur sont donc q=(W,b,S).",
  "183": "En choisis-\nsant un modèle d’observation de produits de lois de Bernoulli ainsi qu’un\ndécodeur linéaire, on retrouve également le modèle (1.13).\nTout l’indérêt est cependant d’aller au delà des modèles linéaires, en\nutilisant plutôt des réseaux profonds tels que décrits plus haut. On pourrait\npar exemple choisir un réseau tel que celui de l’équation (1.1) :\nµq(z)=W1sigmoïde (W0z+b0)+b1, (1.18)\ndans le cas du modèle d’observation gaussien.",
  "184": "On pourrait également\nutiliser un réseau adapté à l’architecture de nos données. Par exemple, si\nles données sont des images, on pourrait choisir un réseau convolutif; si\nles données sont des textes, on pourrait choisir un réseau récurrent. On supposera dans le reste de ce chapitre que\nien p=N(0,Iq), un mo-\ndèle d’observation gaussien (F(h))h=(N(µ,S))µ,Sainsi qu’un décodeur\nlinéaire fq=(µq,Sq), avec µq(z)= Wz+betSq(z)constante égale à S.\nDans ce cas les paramètres du décodeur sont donc q=(W,b,S).",
  "185": "En choisis-\nsant un modèle d’observation de produits de lois de Bernoulli ainsi qu’un\ndécodeur linéaire, on retrouve également le modèle (1.13).\nTout l’indérêt est cependant d’aller au delà des modèles linéaires, en\nutilisant plutôt des réseaux profonds tels que décrits plus haut. On pourrait\npar exemple choisir un réseau tel que celui de l’équation (1.1) :\nµq(z)=W1sigmoïde (W0z+b0)+b1, (1.18)\ndans le cas du modèle d’observation gaussien.",
  "186": "On pourrait également\nutiliser un réseau adapté à l’architecture de nos données. Par exemple, si\nles données sont des images, on pourrait choisir un réseau convolutif; si\nles données sont des textes, on pourrait choisir un réseau récurrent. On supposera dans le reste de ce chapitre que pa une densité p(z)\nvis-à-vis d’une certaine mesure de référence sur Z, et que, pour tout h,\nF(h)a pour densité F(x|h)vis - à-vis d’une mesure de référence sur X.",
  "187": "La\ndensité conditionnelle de zsachant xsera donc pq(z|x)= F(x|fq(z)), et la\nloi marginale des données sera\npq(x)=Z\nXpq(x|z)p(z)dx=Z\nXF(x|fq(z))p(z)dz. (1.19)\nOn sera également amené à regarder la densité de zsachant x, géné-\nralement appelée densité a posteriori , et qui vaut, d’après le théorème de\nBayes\npq(z|x)=pq(x|z)p(z)\npq(x). (1.20)xxiv Chapitre 1. IA et modèles génératifs",
  "188": "Cette densité a posteriori est fondamentale car elle permet d’encoder une\ndonnée x. En effet, la loi de z|xpourra être vue comme une représenta-\ntion d’une certaine donnée de grande dimension x. Notons cependant que\nnotre représentation de xpar sa loi a posteriori n’est pas vraiment une\nréduction de dimension pour l’instant. En effet, la représentation z|xest\nune loi de probabilités sur un espace de petite dimension Z, et non pas\ndirectement un vecteur de petite dimension.",
  "189": "On peut cependant obtenir\nune représentation véritablement de petite dimension en considérant une\nstatistique descriptive de z|x, par exemple sa moyenne E[z|x]. Bien qu’on\nutilise le vocabulaire \"a priori\" et \"a posteriori\", il convient d’insister sur\nle fait que les modèles considérés ici ne sont pas bayésiens. En inférence\nbayésienne, on place une loi a priori sur des paramètres inconnus, aﬁn de\nmodéliser notre incertitude (voir par exemple [ 19]).",
  "190": "Ici, l’a priori est sur des\nvariables latentes, et les paramètres sont traités comme des quantités déter-\nministes. Toutefois, les recettes présentées dans ce chapitre sont applicables\négalement à des modèles bayésiens (voir par exemple [4]). Les notations introduites dans le paragraphe précédent sont quelque\npeu abusives, car on appelle pà la fois les densités de xetz, conditionnelles\nou non.",
  "191": "Ce genre d’abus (tout comme la confusion habituelle entre variable\naléatoire et réalisation) permet toutefois d’alléger considérablement les\nnotations. Remarquons également que l’on a choisi d’ajouter un indice qà\ntoutes les densités qui dépendent du décodeur fq. Cela permettra de repérer\nde manière commode ce qui dépend ou non des paramètres à optimiser\npar maximum de vraisemblance.\n1.5.3 La vraisemblance des modèles profonds à variables latentes",
  "192": "Une approche naturelle pour\n considérés ici ne sont pas bayésiens. En inférence\nbayésienne, on place une loi a priori sur des paramètres inconnus, aﬁn de\nmodéliser notre incertitude (voir par exemple [ 19]). Ici, l’a priori est sur des\nvariables latentes, et les paramètres sont traités comme des quantités déter-\nministes. Toutefois, les recettes présentées dans ce chapitre sont applicables\négalement à des modèles bayésiens (voir par exemple [4]).",
  "193": "Les notations introduites dans le paragraphe précédent sont quelque\npeu abusives, car on appelle pà la fois les densités de xetz, conditionnelles\nou non. Ce genre d’abus (tout comme la confusion habituelle entre variable\naléatoire et réalisation) permet toutefois d’alléger considérablement les\nnotations. Remarquons également que l’on a choisi d’ajouter un indice qà\ntoutes les densités qui dépendent du décodeur fq.",
  "194": "Cela permettra de repérer\nde manière commode ce qui dépend ou non des paramètres à optimiser\npar maximum de vraisemblance.\n1.5.3 La vraisemblance des modèles profonds à variables latentes Une approche naturelle pour estimer les paramètres inconnus qd’un\nmodèle à variables latentes serait d’en maximiser la vraisemblance. Celle-ci\nest égale à\n`(q)=n\nÂ\ni=1logpq(xi)=n\nÂ\ni=1log✓Z\nXpq(xi|z)p(z)dz◆\n(1.21)\n=n\nÂ\ni=1log✓Z\nXF(xi|fq(z))p(z)dz◆\n.",
  "195": "(1.22)\nDans le cas de certains modèles linéaires évoqués précédemment (par\nexemple l’analyse en composantes principales probabiliste ou l’analyse fac-\ntorielle), les nintégrales impliquées dans l’expression de la vraisemblance\npeuvent être explicitement calculées, et `(q)peut être optimisée à l’aide\nd’algorithmes d’optimisation plus ou moins standards. En revanche, dans1.5.",
  "196": "Modèles profonds à variables latentes xxv\n13Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)Illustrative exampleof a DLVM for binaryimages\nDeeplatent variable models(DLVMs)•Latent variable modelsthatleveragedeeplearning.•Includevariationalautoencoders(VAEs) and generativeadversarialnetworks(GANs).•Nonlineargeneralisationof factor analysis, PCA, topic models…\nKingma& Welling(ICLR 2014), Rezendeet al.",
  "197": "(ICML 2014), Goodfellowet al. (NeurIPS2014)\n12Deep latent variable models (DLVMs)(Kingma and Welling, 2014, Rezende, Mohamed & Wierstra (2014))Assume that(xi,zi)i\u0000nare i.i.d. random variables driven by the model:\u0000z⇠p(z)(prior)x⇠p\u0000(x|z)=\u0000(x|f\u0000(z))(observation model)zx\u0000nwhere•z2Rdis thelatentvariable,•x2Xis theobservedvariable,•the functionf\u0000:Rd!His a(deep)",
  "198": "neural networkcalled thedecoder•(\u0000(·|\u0000))\u0000\u0000His a parametric family called theobservation model, usuallyverysimple: unimodal and fully factorised (e.g. multivariate Gaussians or products ofmultinomials)12Deep latent variable models (DLVMs)(Kingma and Welling, 2014, Rezende, Mohamed & Wierstra (2014))Assume that(xi,zi)i\u0000nare i.i.d. random variables driven by the model:\u0000z⇠p(z)(prior)x⇠p\u0000(x|z)=\u0000(x|f\u0000(z))(observation model\n models…\nKingma& Welling(ICLR 2014), Rezendeet al. (ICML 2014), Goodfellowet al.",
  "199": "(NeurIPS2014)\n12Deep latent variable models (DLVMs)(Kingma and Welling, 2014, Rezende, Mohamed & Wierstra (2014))Assume that(xi,zi)i\u0000nare i.i.d. random variables driven by the model:\u0000z⇠p(z)(prior)x⇠p\u0000(x|z)=\u0000(x|f\u0000(z))(observation model)zx\u0000nwhere•z2Rdis thelatentvariable,•x2Xis theobservedvariable,•the functionf\u0000:Rd!His a(deep) neural networkcalled thedecoder•(\u0000(·|\u0000))\u0000\u0000His a parametric family called theobservation model, usuallyverysimple: unimodal and fully factorised (e.g.",
  "200": "multivariate Gaussians or products ofmultinomials)12Deep latent variable models (DLVMs)(Kingma and Welling, 2014, Rezende, Mohamed & Wierstra (2014))Assume that(xi,zi)i\u0000nare i.i.d. random variables driven by the model:\u0000z⇠p(z)(prior)x⇠p\u0000(x|z)=\u0000(x|f\u0000(z))(observation model)zx\u0000nwhere•z2Rdis thelatentvariable,•x2Xis theobservedvariable,•the functionf\u0000:Rd!His a(deep)",
  "201": "neural networkcalled thedecoder•(\u0000(·|\u0000))\u0000\u0000His a parametric family called theobservation model, usuallyverysimple: unimodal and fully factorised (e.g.",
  "202": "multivariate Gaussians or products ofmultinomials)Deepneural network(decoder, generator)1113Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)\n13Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z)",
  "203": "= Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)\nf(z)xj,k⇠Bern(fj,k(z))\n13Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)f(z)xj,k⇠Bern(fj,k(z))\n13Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)f(z)xj,k⇠Bern(fj,k(z))Illustrative exampleof a DLVM for binaryimages",
  "204": "Deeplatent variable models(DLVMs)•Latent variable modelsthatleveragedeeplearning.•Includevariationalautoencoders(VAEs) and generativeadversarialnetworks(GANs).•Nonlineargeneralisationof factor analysis, PCA, topic models…\nKingma& Welling(ICLR \n\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z)",
  "205": "= Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)f(z)xj,k⇠Bern(fj,k(z))\n13Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)f(z)xj,k⇠Bern(fj,k(z))Illustrative exampleof a DLVM for binaryimages Deeplatent variable",
  "206": "models(DLVMs)•Latent variable modelsthatleveragedeeplearning.•Includevariationalautoencoders(VAEs) and generativeadversarialnetworks(GANs).•Nonlineargeneralisationof factor analysis, PCA, topic models…\nKingma& Welling(ICLR 2014), Rezendeet al. (ICML 2014), Goodfellowet al. (NeurIPS2014)\n12Deep latent variable models (DLVMs)(Kingma and Welling, 2014, Rezende, Mohamed & Wierstra (2014))Assume that(xi,zi)i\u0000nare i.i.d. random variables",
  "207": "driven by the model:\u0000z⇠p(z)(prior)x⇠p\u0000(x|z)=\u0000(x|f\u0000(z))(observation model)zx\u0000nwhere•z2Rdis thelatentvariable,•x2Xis theobservedvariable,•the functionf\u0000:Rd!His a(deep) neural networkcalled thedecoder•(\u0000(·|\u0000))\u0000\u0000His a parametric family called theobservation model, usuallyverysimple: unimodal and fully factorised (e.g. multivariate Gaussians or products ofmultinomials)12Deep latent variable models (DLVMs)(Kingma and Welling, 2014, Rezende, Mohamed & Wierstra (2014))Assume that(xi,zi)i\u0000nare i.i.d.",
  "208": "random variables driven by the model:\u0000z⇠p(z)(prior)x⇠p\u0000(x|z)=\u0000(x|f\u0000(z))(observation model)zx\u0000nwhere•z2Rdis thelatentvariable,•x2Xis theobservedvariable,•the functionf\u0000:Rd!His a(deep) neural networkcalled thedecoder•(\u0000(·|\u0000))\u0000\u0000His a parametric family called theobservation model, usuallyverysimple: unimodal and fully factorised (e.g.",
  "209": "multivariate Gaussians or products ofmultinomials)Deepneural network(decoder, generator)1113Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)\n13Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z)",
  "210": "= Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)f(z)xj,k⇠Bern(fj,k(z))\n13Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p\n data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)\n13Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z)",
  "211": "= Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)f(z)xj,k⇠Bern(fj,k(z))\n13Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)f(z)\nxj,k⇠Bern(fj,k(z))\n13Illustrative example",
  "212": "of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)f(z)xj,k⇠Bern(fj,k(z))Illustrative exampleof a DLVM for binaryimages Deeplatent variable",
  "213": "models(DLVMs)•Latent variable modelsthatleveragedeeplearning.•Includevariationalautoencoders(VAEs) and generativeadversarialnetworks(GANs).•Nonlineargeneralisationof factor analysis, PCA, topic models…\nKingma& Welling(ICLR 2014), Rezendeet al. (ICML 2014), Goodfellowet al. (NeurIPS2014)\n12Deep latent variable models (DLVMs)(Kingma and Welling, 2014, Rezende, Mohamed & Wierstra (2014))Assume that(xi,zi)i\u0000nare i.i.d. random variables",
  "214": "driven by the model:\u0000z⇠p(z)(prior)x⇠p\u0000(x|z)=\u0000(x|f\u0000(z))(observation model)zx\u0000nwhere•z2Rdis thelatentvariable,•x2Xis theobservedvariable,•the functionf\u0000:Rd!His a(deep) neural networkcalled thedecoder•(\u0000(·|\u0000))\u0000\u0000His a parametric family called theobservation model, usuallyverysimple: unimodal and fully factorised (e.g. multivariate Gaussians or products ofmultinomials)12Deep latent variable models (DLVMs)(Kingma and Welling, 2014, Rezende, Mohamed & Wierstra (2014))Assume that(xi,zi)i\u0000nare i.i.d.",
  "215": "random variables driven by the model:\u0000z⇠p(z)(prior)x⇠p\u0000(x|z)=\u0000(x|f\u0000(z))(observation model)zx\u0000nwhere•z2Rdis thelatentvariable,•x2Xis theobservedvariable,•the functionf\u0000:Rd!His a(deep) neural networkcalled thedecoder•(\u0000(·|\u0000))\u0000\u0000His a parametric family called theobservation model, usuallyverysimple: unimodal and fully factorised (e.g.",
  "216": "multivariate Gaussians or products ofmultinomials)Deepneural network(decoder, generator)1113Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nz))(observation model)zx\u0000nwhere•z2Rdis thelatentvariable,•x2Xis theobservedvariable,•the functionf\u0000:Rd!His a(deep) neural networkcalled thedecoder•(\u0000(·|\u0000))\u0000\u0000His a parametric family called theobservation model, usuallyverysimple: unimodal and fully factorised (e.g.",
  "217": "multivariate Gaussians or products ofmultinomials)12Deep latent variable models (DLVMs)(Kingma and Welling, 2014, Rezende, Mohamed & Wierstra (2014))Assume that(xi,zi)i\u0000nare i.i.d. random variables driven by the model:\u0000z⇠p(z)(prior)x⇠p\u0000(x|z)=\u0000(x|f\u0000(z))(observation model)zx\u0000nwhere•z2Rdis thelatentvariable,•x2Xis theobservedvariable,•the functionf\u0000:Rd!His a(deep)",
  "218": "neural networkcalled thedecoder•(\u0000(·|\u0000))\u0000\u0000His a parametric family called theobservation model, usuallyverysimple: unimodal and fully factorised (e.g.",
  "219": "multivariate Gaussians or products ofmultinomials)Deepneural network(decoder, generator)1113Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)\n13Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z)",
  "220": "= Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)f(z)xj,k⇠Bern(fj,k(z))\n13Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)f(z)xj,k⇠Bern(fj,k(z))\n13Illustrative example of a DLVMTraining data{x1,...,xn}binary MNIST\nGenerative modelforz2R2andx2{0,1}28\u000028\u0000\u0000\u0000\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)f(z)xj,k⇠Bern(fj,k(z))\nz⇠\u0000\n<latexit sha1_base64=\"u49trcKsEQ0vfFpuXNKVWfCvR+s=\">AAACzXicjVHLSsNAFD2Nr1pfVZdugkVwVZIq6LLoxp0V7APbIsl0WofmRTIRatWtP+BWf0v8A/0L74wpqEV0QpIz595zZu69buSJRFrWa86YmZ2bX8gvFpaWV1bXiusbjSRMY8brLPTCuOU6CfdEwOtSSI+3opg7vuvxpjs8VvHmNY8TEQbnchTxru8MAtEXzJFEXdyYnUT4ZicSl8WSVbb0MqeBnYESslULiy/ooIcQ\n\u0000\u0000z⇠N\u000000\u0000,1001\u0000\u0000xj,k⇠Bernoulli(p=fj,k(z))Decoder networkf(z) = Sigmoid(Vtanh(Wz+b)+\u0000)Generationz⇠N\u000000\u0000,1001\u0000\u0000z=(\u00001.2033,0.5340)f(z)xj,k⇠Bern(fj,k(z))\nz⇠\u0000\n<latexit sha1_base64=\"u49trcKsEQ0vfFpuXNKVWfCvR+s=\">AAACzXicjVHLSsNAFD2Nr1pfVZdugkVwVZIq6LLoxp0V7APbIsl0WofmRTIRatWtP+BWf0v8A/0L74wpqEV0QpIz595zZu69buSJRFrWa86YmZ2bX8gvFpaWV1bXiusbjSRMY8brLPTCuOU6CfdEwOtSSI+3opg7vuvxpjs8VvHmNY8TEQbnchTxru8MAtEXzJFEXdyYnUT4ZicSl8WSVbb0MqeBnYESslULiy/ooIcQDCl8cASQhD04SOhpw4aFiLguxsTFhISOc9yhQNqUsjhlOMQO6TugXTtjA9orz0SrGZ3i0RuT0sQOaULKiwmr00wdT7WzYn/zHmtPdbcR/d3MyydW4orYv3STzP/qVC0SfRzqGgTVFGlGVccyl1R3Rd3c/FKVJIeIOIV7FI8JM62c9NnUmkTXrnrr6PibzlSs2rMsN8W7uiUN2P45zmnQqJTtvXLlbL9UPcpGnccWtrFL8zxAFSeooU7eAR7xhGfj1EiNW+P+M9XIZZpNfFvGwwczQpL3</latexit>fˆ\u0000(z)\n<latexit sha1_base64=\"YHO1SemYz8qtaz7b9NKCg9gpRaQ=\">AAAC2HicjVHLTsJAFD3UF+KrytJNIzHBDSlookuiG5eYyCMCIdMyQENpm3ZqgoTEnXHrD7jVLzL+gf6Fd8aSqMToNG3PnHvPmbn3WoHrRMI0X1PawuLS8kp6NbO2vrG5pW/v1CI/Dm1etX3XDxsWi7jreLwqHOHyRhByNrJcXreGZzJev+Zh5PjepRgHvD1ifc/pOTYTRHX0bK8zaQ2YmLTEgAs2neZvDjp6ziyYahnzoJiAHJJV8fUXtNCFDxsxRuDwIAi7YIjoaaIIEwFxbUyICwk5Ks4xRYa0MWVxymDEDunbp10zYT3aS89IqW06xaU3JKWBfdL4lBcSlqcZKh4rZ8n+5j1RnvJuY/pbideIWIEBsX/pZpn/1claBHo4UTU4VFOgGFmdnbjEqivy5saXqgQ5BMRJ3KV4SNhWylmfDaWJVO2yt0zF31SmZOXeTnJjvMtb0oCLP8c5D2qlQvGwULo4ypVPk1GnsYs95GmexyjjHBVUyXuMRzzhWbvSbrU77f4zVUslmiy+Le3hA7yjl3k=</latexit>x⇠28\u000028\u0000j=1B([fˆ\u0000(z)]j)\n<latexit sha1_base64=\"wkdZXS8ZF84S19mV/MQIIBn/7e0=\">AAADC3icjVHLbtQwFD0Nr\nAs2neZvDjp6ziyYahnzoJiAHJJV8fUXtNCFDxsxRuDwIAi7YIjoaaIIEwFxbUyICwk5Ks4xRYa0MWVxymDEDunbp10zYT3aS89IqW06xaU3JKWBfdL4lBcSlqcZKh4rZ8n+5j1RnvJuY/pbideIWIEBsX/pZpn/1claBHo4UTU4VFOgGFmdnbjEqivy5saXqgQ5BMRJ3KV4SNhWylmfDaWJVO2yt0zF31SmZOXeTnJjvMtb0oCLP8c5D2qlQvGwULo4ypVPk1GnsYs95GmexyjjHBVUyXuMRzzhWbvSbrU77f4zVUslmiy+Le3hA7yjl3k=</latexit>x⇠28\u000028\u0000j=1B([fˆ\u0000(z)]j)\n<latexit sha1_base64=\"wkdZXS8ZF84S19mV/MQIIBn/7e0=\">AAADC3icjVHLbtQwFD0Nr1JeAyzZWIyQpptRMkViNkhVKyGWRWLaSpMhcjyejtu8ZDuINson8Cfs2CG2/YFuEIIPgL/g2qQSUCFwlOT43HuOfe9Nq0wZG4afV4JLl69cvbZ6fe3GzVu37/Tu3ts1Za2FnIgyK/V+yo3MVCEnVtlM7lda8jzN5F56tO3ie6+lNqosXtrjSs5yflCohRLcEpX0nr1hsVE5iytdzpPm8GnUvmpGYxZblUvDRuOWxTm3S8GzZqsdTBdJEy+5bWK7lJa37eBkfZYcrie9fjgM/WIXQdSBPrq1U/Y+IcYcJQRq5JAoYAln4DD0TBEhREXcDA1xmpDycYkWa6StKUtSBif2iL4HtJt2bEF752m8WtApGb2alAyPSFNSnibsTmM+Xntnx/7Nu/Ge7m7H9E87r5xYiyWx/9KdZ/6vztViscDY16CopsozrjrRudS+K+7m7JeqLDlUxDk8p7gmLLzyvM/Ma4yv3fWW+/g3n+lYtxddbo3v7pY04OjPcV4Eu6NhtDEcvXjc39zqRr2KB3iIAc3zCTbxHDuYkPc7nOELvgZvg/fBh+Djz9RgpdPcx28rOP0B/i6rXg==</latexit>Donn´ ees d’entraˆ ınement<latexit sha1_base64=\"+DGDYXdHwJs97qLXs3776Wtut3w=\">AAAC8XicjVFBT9RAGH1UEVhBiyRcvDRuCJw27XqQIwEPHjFx2U3WjWnLAJNtO810arIh/Alu3AhX/4BX/RPEf6AXf4NvZrtR2RCdSTtv3vd9b+abl5SZrEwYflvwHjxcfLS0vNJ6vLr25Km//uyoUrVORS9VmdKDJK5EJgvRM9JkYlBqEedJJvrJ+MDG+x+FrqQq3plJKUZ5fFrIE5nGhpTyN/EaCgXnDwhUCHCMbaICBhoxfhIJ5FPmg98OO6EbwTyIGtBGMw6Vf4v3FFRIUc9EiDMKV5xDRAhRkhvhnJwmki4ucIEWa2tmCWbEZMf8n3I\nvg/fBh+Djz9RgpdPcx28rOP0B/i6rXg==</latexit>Donn´ ees d’entraˆ ınement<latexit sha1_base64=\"+DGDYXdHwJs97qLXs3776Wtut3w=\">AAAC8XicjVFBT9RAGH1UEVhBiyRcvDRuCJw27XqQIwEPHjFx2U3WjWnLAJNtO810arIh/Alu3AhX/4BX/RPEf6AXf4NvZrtR2RCdSTtv3vd9b+abl5SZrEwYflvwHjxcfLS0vNJ6vLr25Km//uyoUrVORS9VmdKDJK5EJgvRM9JkYlBqEedJJvrJ+MDG+x+FrqQq3plJKUZ5fFrIE5nGhpTyN/EaCgXnDwhUCHCMbaICBhoxfhIJ5FPmg98OO6EbwTyIGtBGMw6Vf4v3FFRIUc9EiDMKV5xDRAhRkhvhnJwmki4ucIEWa2tmCWbEZMf8n3I3bNiC+9xd2lanPCXjp1kZYIs1inma2J4WuHjtlC17n/a507R3m3BNGq2crMEZ2X/VzTL/t872YnCCXdeDZE+lY2x3aaNSu1exNw/+6MpQoSSnnWWSq2CF+W2W63xqaereNnbx7y7TsnafNrk17ectaXB01855cNTtRC873bfd9t5+Y/UynuMFdujnK+zhDQ7Ro/YlPuMLvnqVd+VdezfTVG+hqdnAX8P79AuhXZpq</latexit>Tirage ` a partir du mod` ele entraˆ ın´ epˆ\u0000\n<latexit sha1_base64=\"niIYqcu71NKrxdyqXXCI/0o6tbk=\">AAADL3icjVJNT9tAFJy4QClfdemxF4uAxClyUlXtEbUXjlQigARRZG82YOEv2etKEcqP6j/pDfVScYRLj722sy8bVS1CsJadt7Nv3nuzk7hMk9qE4feW92xhcen58ouV1bX1jZf+q82jumgqpfuqSIvqJI5qnSa57pvEpPqkrHSUxak+ji8/2fPjL7qqkyI/NJNSD7LoPE/GiYoMocJ/h0MkqBDhHBoBbviW3FUwggcYoeE3Q8HoFqlkaeQ8t6yfjO6IbJM1xBXOcEHUSGQYa34jTPlsD/122AllBfeDrgvacOug8K9ZZMTGiiNkrqniCBFqPqfoImRbgwHbzUdWMuIUK+Q2zNIiR+HSSTx1aM69rVkLW7FLyrciM8AOOQXzrHzbLZDzRipb9KHaV1LTzjbhb+xqZXIhF0Qf480zn8qzWgzG+CAaEmoqBbHqlKvSyK3MbPuryppSEpsZbI3WZFjm/J4D4dSiPRKr7fmtZFrU7pXLbfgX4JQ0uPu/nfeDo16n+7bT+9xr7310Vi/jDbawSz/fYw/7OECftb/hF3634H31rr0f3s0s1Ws5zmv8s7y7Pznvp/8=</latexit>\nFIGURE 1.2– Exemple d’un modèle profond à variables latentes utilisant un\nespace latent de deux dimensions pour modéliser MNIST.\nles cas qui nous intéressent impliquant des réseaux de neurones profonds\nen guide de fq, ces intégrales n’ont pas géné\ncEHUSGQYa34jTPlsD/122AllBfeDrgvacOug8K9ZZMTGiiNkrqniCBFqPqfoImRbgwHbzUdWMuIUK+Q2zNIiR+HSSTx1aM69rVkLW7FLyrciM8AOOQXzrHzbLZDzRipb9KHaV1LTzjbhb+xqZXIhF0Qf480zn8qzWgzG+CAaEmoqBbHqlKvSyK3MbPuryppSEpsZbI3WZFjm/J4D4dSiPRKr7fmtZFrU7pXLbfgX4JQ0uPu/nfeDo16n+7bT+9xr7310Vi/jDbawSz/fYw/7OECftb/hF3634H31rr0f3s0s1Ws5zmv8s7y7Pznvp/8=</latexit>\nFIGURE 1.2– Exemple d’un modèle profond à variables latentes utilisant un\nespace latent de deux dimensions pour modéliser MNIST.\nles cas qui nous intéressent impliquant des réseaux de neurones profonds\nen guide de fq, ces intégrales n’ont pas généralement de forme simple.\nComme ces intégrales sont des espérances, une approche naturelle serait\nd’estimer celles-ci à l’aide d’une méthode de Monte Carlo.",
  "221": "C’est l’idée\nderrière l’inférence variationnelle par échantillonnage préférentiel.\n1.5.4 Inférence variationnelle par échantillonnage préférentiel Notre objectif est d’approcher\nlogpq(xi)= log✓Z\nXF(xi|fq(z))p(z)dz◆\n, (1.23)\npour un certain i2{1,...,n}, à l’aide d’une méthode de Monte Carlo. Une\napproche simple serait de tirer quelques z1,...,zK⇠pindépendants, puis\nde regarder l’approximation\nZ\nXF(xi|fq(z))p(z)dz⇡IK(xi)=1\nKK\nÂ\nk=1F(xi|fq(zk)).",
  "222": "(1.24)\nLa loi des grands nombres et la linéarité de l’espérance assurent que IK(xi)\nest un estimateur sans biais et consistant de l’intégrale. Lorsqu’un estima -xxvi Chapitre 1. IA et modèles génératifs\nteur est sans biais, une manière commode de quantiﬁer sa précision est\nsimplement de regarder sa variance. Dans ce cas,\nVar(IK(xi)) =Var(F(xi|fq(z1)))\nK. (1.25)\nLa variance décroîtra donc en O(1/K), mais risque de demeurer grande\nsiVar(F(xi|fq(z1)))l’est.",
  "223": "Une manière classique de modiﬁer l’estimateur\nde Monte Carlo aﬁn de réduire se variance est de faire de l’échantillonage\npréférentiel .",
  "224": "L’idée est d’introduire une nouvelle densité de probabilité q(z),\ndont le support contient celui de p(z), et d’écrire\nZ\nXF(xi|fq(z))p(z)dz=Z\nXF(xi|fq(z))p(z)\nq(z)q(z)dz (1.26)\n⇡Iq\nK(xi)=1\nKK\nÂ\nk=1F(xi|fq(zk))p(zk)\nq(zk), (1.27)\noù les z1,...,zKsont désormais tirés selon la loi de qplutôt que p. La\ncondition de support assure que le dénominateur ne sera jamais nul.\nEst-ce que ce nouvel estimateur Iq\nK(xi)est meilleur que l’estimateur\nsimple IK(xi)?",
  "225": "Pour les mêmes raisons, Iq\nK(xi)est également consistant et\nsans biais, mais qu’en est-il de sa variance? La réponse dépend du choix\nde la densité de proposition q. Étonnamment, il est possible de choisir\nune certaine q⇤\nitelle que Var(Iq⇤\ni\nK(xi)) = 0, c’est à dire qu’un seul tirage de\nMonte Carlo suf�\nduire se variance est de faire de l’échantillonage\npréférentiel .",
  "226": "L’idée est d’introduire une nouvelle densité de probabilité q(z),\ndont le support contient celui de p(z), et d’écrire\nZ\nXF(xi|fq(z))p(z)dz=Z\nXF(xi|fq(z))p(z)\nq(z)q(z)dz (1.26)\n⇡Iq\nK(xi)=1\nKK\nÂ\nk=1F(xi|fq(zk))p(zk)\nq(zk), (1.27)\noù les z1,...,zKsont désormais tirés selon la loi de qplutôt que p. La\ncondition de support assure que le dénominateur ne sera jamais nul.\nEst-ce que ce nouvel estimateur Iq\nK(xi)est meilleur que l’estimateur\nsimple IK(xi)?",
  "227": "Pour les mêmes raisons, Iq\nK(xi)est également consistant et\nsans biais, mais qu’en est-il de sa variance? La réponse dépend du choix\nde la densité de proposition q. Étonnamment, il est possible de choisir\nune certaine q⇤\nitelle que Var(Iq⇤\ni\nK(xi)) = 0, c’est à dire qu’un seul tirage de\nMonte Carlo sufﬁt pour estimer parfaitement notre intégrale!",
  "228": "En effet, en\nchoisissant\nq⇤\ni(z)= pq(z|xi)=F(xi|fq(z))p(z)\npq(xi), (1.28)\non voit que Iq⇤\ni\nK(xi)= p(xi)pour tout K.\nMalheureusement, tirer selon la loi de densité q⇤\ni(z)= pq(z|xi)n’est\npas chose aisée. Des méthodes de Monte Carlo par chaînes de Markov\npourraient être utilisées à cette ﬁn, mais à un coût calculatoire très impor-\ntant.",
  "229": "Ici, nous préférons voir cette loi idéale non pas comme un objectif en\nsoi, mais comme une raison d’espérer qu’en choisissant \"raisonnablement\"\nune loi de proposition, l’échantillonage préférentiel peut fonctionner beau-\ncoup mieux qu’un estimateur de Monte Carlo simple. Notre objectif sera\nainsi de choisir des densités de propositions q1,...,qnaﬁn d’approcher au mieux\nlogp(x1), ..., log p(xn).",
  "230": "Une idée naturelle serait de choisir ces q1,...,qndans une famille pa-\nramétrée de densités (Y(z|k))k2KsurZ(par exemple si Zest un espace\neuclidien, on pourrait choisir une famille de gaussiennes multivariées).1.5. Modèles profonds à variables latentes xxvii\nCela veut dire que choisir q1,...,qnreviendra à choisir des paramètres\nk1,...,kn2Kpour chacune des lois de proposition. Dans le cas de proposi-\ntions gaussiennes, cela impliquerait de choisir nmoyennes et nmatrices de\ncovariances.",
  "231": "Cependant, dans les situations qui nous intéressent, le nombre\nd’observations nest généralement très grand (avec peu d’observations,\nentraîner des réseaux de neurones profonds est peu indiqué). Cela veut\ndire que choisir ces k1,...,knsera difﬁcile et coûteux en mémoire. On va\nmontrer ici une autre solution, appelée inférence variationnelle amortie . L’idée\nde base est assez simple : plutôt que de choisir une valeur de kpour chaque\nxi, on va apprendre une fonction envoyant xvers le kcorrespondant.",
  "232": "Cette fonc-\ntion, qu’on appellera g:X\u0000 ! K , sera appelée encodeur , car elle envoie\ndes données xvers une distribution Y(g(x))sur l’espace des codes. Nous\nallons à nouveau modéliser cette fonction à l’aide d’un réseau de neurones,\ndont les paramètres sont stockés dans un vecteur g2G, on notera donc gg.\nEn deﬁnitive, notre proposition sera donc, pour chaque point xi\nqi(z)= Y(z|gg(xi)).",
  "233": "(1.29)\nIl est commode de voir ces distributions non pas comme une suite de n\ndistributions, mais comme des lois conditionnelles toutes paramétrées par\nun même g\n de\ncovariances. Cependant, dans les situations qui nous intéressent, le nombre\nd’observations nest généralement très grand (avec peu d’observations,\nentraîner des réseaux de neurones profonds est peu indiqué). Cela veut\ndire que choisir ces k1,...,knsera difﬁcile et coûteux en mémoire.",
  "234": "On va\nmontrer ici une autre solution, appelée inférence variationnelle amortie . L’idée\nde base est assez simple : plutôt que de choisir une valeur de kpour chaque\nxi, on va apprendre une fonction envoyant xvers le kcorrespondant. Cette fonc-\ntion, qu’on appellera g:X\u0000 ! K , sera appelée encodeur , car elle envoie\ndes données xvers une distribution Y(g(x))sur l’espace des codes.",
  "235": "Nous\nallons à nouveau modéliser cette fonction à l’aide d’un réseau de neurones,\ndont les paramètres sont stockés dans un vecteur g2G, on notera donc gg.\nEn deﬁnitive, notre proposition sera donc, pour chaque point xi\nqi(z)= Y(z|gg(xi)). (1.29)\nIl est commode de voir ces distributions non pas comme une suite de n\ndistributions, mais comme des lois conditionnelles toutes paramétrées par\nun même g:\nqi(z)= qg(z|xi), (1.30)\noù, pour tout x2X,\nqg(z|x)= Y(z|gg(x)).",
  "236": "(1.31)\nL’intérêt de déﬁnir cette loi conditionnelle qg(z|x)est multiple :\n—nous n’aurons pas à apprendre une loi qipour chaque point de\ndonnées mais une seule loi conditionnelle;\n—si nous sommes en présence d’un nouveau point exqui n’était pas\ndans la base de données initiale, nous pouvons aisément calculer\nune proposition adéquate, en encodant xet calculant qg(z|x);\n—nous pouvons choisir un type d’architecture pertinent pour ggen\nfonction de nos données.",
  "237": "Par exemple, dans le cas d’images, nous\npourrions considérer un réseau convolutif.\nEn déﬁnitive, notre estimateur de la log-vraisemblance sera\n`(q)⇡L K(q,g)=n\nÂ\ni=1Ezi1,...,ziK⇠qg(z|xi)\"\nlog \n1\nKK\nÂ\nk=1F(xi|fq(zik))p(zik)\nqg(zik|x)! #\n.\n(1.32) L’idée sera de maximiser LK(q,g)plutôt que la vraisemblance `(q). Cela\npose tout de suite quelques questions :xxviii Chapitre 1. IA et modèles génératifs",
  "238": "—Est-il vraiment plus facile de maximiser LK(q,g)que`(q)?Après tout,\nLK(q,g)est également composé de nespérance à priori difﬁciles à\ncalculer. Cependant, en tirant à l’aide de qg(z|x)il est possible de\ncalculer un estimateur sans biais du gradient de LK(q,g), comme\nexpliqué par exemple par Mohamed et ses coauteurs [ 16]. Cela\npermet ainsi de maximiser LK(q,g)à l’aide de l’algorithme du\ngradient stochastique (voir par exemple la revue de littérature de\nBottou, Curtis et Nocedal [1]). —",
  "239": "On a introduit un paramètre en plus : g. Que fait-on de lui? En fait,\non va tout simplement maximiser LK(q,g)à la fois en get en\nq! Pourquoi est-ce pertinent? Pour tous q,g, l’inégalité de Jensen\nappliqué au logarithme entraine `(q)>LK(q,g). Ansi, à qﬁxé,\nla meilleure approximation de `(q)qui puisse s’écrire comme un\nLK(q,g)sera\n`(q)⇡max\ng2GLK(q,g).",
  "240": "(1.33)\nLe fait que notre approximation est une borne inférieure de la\nvraisemblance justiﬁe le nom \"evidence lower bound\" pour désigner\nLK(q,g).\n—Quelle est l’inﬂuence du nombre de tirages K?Intuitivement, il faudrait\nchoisir Kaussi grand que possible\n)il est possible de\ncalculer un estimateur sans biais du gradient de LK(q,g), comme\nexpliqué par exemple par Mohamed et ses coauteurs [ 16].",
  "241": "Cela\npermet ainsi de maximiser LK(q,g)à l’aide de l’algorithme du\ngradient stochastique (voir par exemple la revue de littérature de\nBottou, Curtis et Nocedal [1]). — On a introduit un paramètre en plus : g. Que fait-on de lui? En fait,\non va tout simplement maximiser LK(q,g)à la fois en get en\nq! Pourquoi est-ce pertinent? Pour tous q,g, l’inégalité de Jensen\nappliqué au logarithme entraine `(q)>LK(q,g).",
  "242": "Ansi, à qﬁxé,\nla meilleure approximation de `(q)qui puisse s’écrire comme un\nLK(q,g)sera\n`(q)⇡max\ng2GLK(q,g). (1.33)\nLe fait que notre approximation est une borne inférieure de la\nvraisemblance justiﬁe le nom \"evidence lower bound\" pour désigner\nLK(q,g).\n—Quelle est l’inﬂuence du nombre de tirages K?Intuitivement, il faudrait\nchoisir Kaussi grand que possible.",
  "243": "On peut en effet prouver (voir\npar exemple [14]) que\nLK+1(q,g)>LK(q,g), (1.34)\nc’est à dire que l’approximation devient de plus en plus précise\nquand Kgrandit. Domke et Sheldon [ 4] on également prouvé, au\nprix d’hypothèse sur les moments des poids de l’échantillonnage\npréférentiel, que LK(q,g)converge vers `(q)à vitesse O(1/K). Il s’agirait donc idéalement de chosir Ktrès grand.",
  "244": "Cependant,\nplus Ksera grand, et plus il sera computationnellement coûteux\nd’optimiser LK(q,g).\nEn déﬁnitive, on a donc un moyen relativement simple d’apprendre les\nparamètres inconnus de notre modèle à variables latentes, applicable dans\nde nombreuses situations.",
  "245": "En effet, l’inférence par échantillange préférentiel\ntelle que rapidement décrite ici, a été appliquée dans de nombreux cadres :\nsi elle a été introduite en premier lieu pour des modèles profonds à variables\nlatentes [ 2], cette technique a par exemple été appliquée à l’apprentissage\nde processus gaussiens [ 21], de modèles séquentiels [ 12,17,11], de modèles\nde graphes aléatoires [ 24], à l’apprentissage avec données manquantes\n[13, 6, 7], ou à l’inférence bayésienne en général [4].1.6.",
  "246": "Conclusion xxix\n1.6 Conclusion Allant du général au particulier , nous nous sommes attachés à offrir\nun panorama de l’IA dans sa diversité (des modèles symboliques à l’ap-\nprentissage), suivi d’un zoom sur certains modèles statistiques récents.",
  "247": "Cette progression sera également l’objectif de la série de cours basés sur\nce chapitre : situer l’IA comme champ interdisciplinaire, et détailler un\nexemple (les modèles profonds à variables latentes), des mathématiques à\nl’implémentation.\nBibliographie\n[1]L.BOTTOU , F. E. CURTIS et J.NOCEDAL : Optimization methods for\nlarge-scale machine learning. SIAM Review , 60(2):223–311, 2018.\n[2]Y.BURDA , R.GROSSE et R. SALAKHUTDINOV : Importance weighted\nautoencoders. In International Conference on",
  "248": "Learning Representations ,\n2016.\n[ 3]J.CHIQUET , M.MARIADASSOU et S. ROBIN : Variational inference for\nprobabilistic poisson PCA. The Annals of Applied Statistics , 12(4):2674–\n2698, 2018.\n[4]J.DOMKE et D. R. SHELDON : Importance weighting and variational\ninference. In Advances in neural information processing systems , p. 4470–\n4479, 2018.\n[5]J.HA\n sa diversité (des modèles symboliques à l’ap-\nprentissage), suivi d’un zoom sur certains modèles statistiques récents.",
  "249": "Cette progression sera également l’objectif de la série de cours basés sur\nce chapitre : situer l’IA comme champ interdisciplinaire, et détailler un\nexemple (les modèles profonds à variables latentes), des mathématiques à\nl’implémentation.\nBibliographie\n[1]L.BOTTOU , F. E. CURTIS et J.NOCEDAL : Optimization methods for\nlarge-scale machine learning. SIAM Review , 60(2):223–311, 2018.\n[2]Y.BURDA , R.GROSSE et R. SALAKHUTDINOV : Importance weighted\nautoencoders. In International Conference on",
  "250": "Learning Representations ,\n2016.\n[ 3]J.CHIQUET , M.MARIADASSOU et S. ROBIN : Variational inference for\nprobabilistic poisson PCA. The Annals of Applied Statistics , 12(4):2674–\n2698, 2018.\n[4]J.DOMKE et D. R. SHELDON : Importance weighting and variational\ninference. In Advances in neural information processing systems , p. 4470–\n4479, 2018.\n[5]J.HAUGELAND :Artiﬁcial Intelligence : The Very Idea .",
  "251": "Massachusetts\nInstitute of Technology, USA, 1985.\n[6]N. B. IPSEN , P.-A. MATTEI et J.FRELLSEN : not-MIWAE : Deep gene-\nrative modelling with missing not at random data. In International\nConference on Learning Representations , 2021.\n[ 7]N. B. IPSEN , P.-A. MATTEI et J. FRELLSEN : How to deal with mis-\nsing data in supervised deep learning? In International Conference on\nLearning Representations , 2022.\n[ 8]K. G. JÖRESKOG : A general approach to conﬁrmatory maximum\nlikelihood factor analysis.",
  "252": "Psychometrika , 34(2):183–202, 1969.\n[ 9]D. P. KINGMA et M. WELLING : Auto-encoding variational Bayes. In\nInternational Conference on Learning Representations , 2014. [10] M. J. KUSNER , B.PAIGE et J. M. HERNÁNDEZ -LOBATO : Grammar va-\nriational autoencoder. In Proceedings of the 34th International Conference\non Machine Learning-Volume 70 , p. 1945–1954. JMLR. org, 2017.xxx BIBLIOGRAPHIE\n[11] T. A. LE, M.IGL,T .RAINFORTH ,T .JINet F.WOOD : Auto-encoding\nsequential Monte Carlo .",
  "253": "In International Conference on Learning Repre-\nsentations , 2018.\n[12] C. J. MADDISON , J.LAWSON , G.TUCKER , N.HEESS, M. NOROUZI ,\nA.MNIH,A .DOUCET et Y. TEH: Filtering variational objectives. In\nAdvances in Neural Information Processing Systems , p. 6573–6583, 2017. [13] P.-A. MATTEI et J.FRELLSEN : MIWAE : Deep generative modelling\nand imputation of incomplete data sets. In International Conference on Machine Learning , p. 4413–4423, 2019. [ 14]",
  "254": "P.-A. MATTEI et J. FRELLSEN : Uphill roads to variational tight-\nness : Monotonicity and Monte Carlo objectives. arXiv preprint\narXiv :2201.10989 , 2022.\n[15] W.MCCULLOCH et W. PITTS : A logical calculus of ideas immanent in\nnervous activity. Bulletin of Mathematical Biophysics , 5:127–147, 1943.\n[16] S.MOHAMED , M.ROSCA , M.FIGURNOV et A. MNIH: Monte Carlo\ngradient estimation in machine learning. Journal of Machine Learning\nResearch , 21(132):1–62, 2020.\n[17]",
  "255": "C.NAESSETH , S.LINDERMAN , R.RANGANATH et D. BLEI: Varia-\ntional sequential Monte Carlo. In International Conference on Artiﬁcial\nIntelligence and Statistics , p. 968–977, 2018.\n[ 18]\n In\nAdvances in Neural Information Processing Systems , p. 6573–6583, 2017. [13] P.-A. MATTEI et J.FRELLSEN : MIWAE : Deep generative modelling\nand imputation of incomplete data sets. In International Conference on Machine Learning , p. 4413–4423, 2019. [ 14]",
  "256": "P.-A. MATTEI et J. FRELLSEN : Uphill roads to variational tight-\nness : Monotonicity and Monte Carlo objectives. arXiv preprint\narXiv :2201.10989 , 2022.\n[15] W.MCCULLOCH et W. PITTS : A logical calculus of ideas immanent in\nnervous activity. Bulletin of Mathematical Biophysics , 5:127–147, 1943.\n[16] S.MOHAMED , M.ROSCA , M.FIGURNOV et A. MNIH: Monte Carlo\ngradient estimation in machine learning. Journal of Machine Learning\nResearch , 21(132):1–62, 2020.\n[17]",
  "257": "C.NAESSETH , S.LINDERMAN , R.RANGANATH et D. BLEI: Varia-\ntional sequential Monte Carlo. In International Conference on Artiﬁcial\nIntelligence and Statistics , p. 968–977, 2018.\n[ 18] D.REZENDE , S.MOHAMED et D. WIERSTRA : Stochastic backpro-\npagation and approximate inference in deep generative models. In\nProceedings of the 31st International Conference on Machine Learning , p.\n1278–1286, 2014.\n[19 ] C.ROBERT : Le choix bayésien : Principes et pratique .",
  "258": "Springer Science &\nBusiness Media, 2005.\n[20] S.RUSSELL et P. NORVIG : Artiﬁcial Intelligence : A Modern Approach .\nPrentice Hall, 3 édn, 2010.\n[21] H.SALIMBENI ,V .DUTORDOIR , J.HENSMAN et M. DEISENROTH : Deep\nGaussian processes with importance-weighted variational inference.\nInK.CHAUDHURI et R. SALAKHUTDINOV , éds : Proceedings of the 36th\nInternational Conference on Machine Learning , vol. 97 de Proceedings of\nMachine Learning Research , p. 5589–5598. PMLR, 09–15 Jun 2019.\n[ 22] H. A. SIMON :",
  "259": "Why should machines learn? InR.MICHALSKI , J.CAR-\nBONNEL et T. MITCHELL , éds : Machine Learning : An Artiﬁcial Intelli-\ngence Approach , p. 25–37. Tioga, Palo Alto, CA, 1983.\n[23] S. M. STIGLER : The epic story of maximum likelihood. Statistical\nScience , p. 598–620, 2007.BIBLIOGRAPHIE xxxi\n[24] L. S. L. TANet N. FRIEL : Bayesian variational inference for exponential\nrandom graph models. Journal of Computational and Graphical Statistics ,\n29(4):910–928, 2020.\n[25] M. E. TIPPING et C. M. BISHOP :",
  "260": "Probabilistic principal component\nanalysis. Journal of the Royal Statistical Society : Series B (Statistical\nMethodology) , 61(3):611–622, 1999.\n[26] A. M. TURING : Computing machinery and intelligence. Mind , 59(236):\n433–460, 1950.\n[27] A. W. Van der VAART :Asymptotic statistics . Cambridge university\npress, 2000.\n, 2020.\n[25] M. E. TIPPING et C. M. BISHOP : Probabilistic principal component\nanalysis.",
  "261": "Journal of the Royal Statistical Society : Series B (Statistical\nMethodology) , 61(3):611–622, 1999.\n[26] A. M. TURING : Computing machinery and intelligence. Mind , 59(236):\n433–460, 1950.\n[27] A. W. Van der VAART :Asymptotic statistics . Cambridge university\npress, 2000."
}